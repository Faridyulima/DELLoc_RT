{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1b985c-57c2-4a8f-ad98-5272a6f0df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48db2213-786a-4a0d-bc29-56da1893be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = 992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd0da90-d4e3-4c1a-ac72-60c10d2c6e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Load data ===\n",
    "df = pd.read_excel('2. Dataset Tampere.xlsx')  # Replace with your actual filename\n",
    "# Load test data\n",
    "DT = pd.read_excel('2. Datatest Tampere.xlsx')  # unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e431c-f951-4d60-a435-809b27af7791",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5544e888-126e-41ef-a0a9-6060cb2f75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\AppData\\Local\\Temp\\ipykernel_6576\\2724756925.py:93: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[rssi_columns] = df[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
      "C:\\Users\\KMITL\\AppData\\Local\\Temp\\ipykernel_6576\\2724756925.py:97: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[rssi_columns] = df[rssi_columns].div(row_max, axis=0).fillna(0)\n",
      "C:\\Users\\KMITL\\AppData\\Local\\Temp\\ipykernel_6576\\2724756925.py:102: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[rssi_columns] = df[rssi_columns].applymap(\n"
     ]
    }
   ],
   "source": [
    "# Linear Normalization to [0,1] Using Dataset Minimum\n",
    "\n",
    "'''rssi_columns = df.columns[:raw_features]  # assuming RSSI is in the first `raw_features` columns\n",
    "\n",
    "# === Step 2: Replace 100 (no signal) with 0 ===\n",
    "df[rssi_columns] = df[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 3: Compute minimum RSSI value (exclude 0s from consideration)\n",
    "# Only consider values < 0 (i.e., actual signal readings), ignore 0 (no signal)\n",
    "rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "\n",
    "# === Step 4: Apply linear normalization\n",
    "# Keep 0s as 0 (representing no signal), and normalize only values < 0\n",
    "df[rssi_columns] = df[rssi_columns].applymap(\n",
    "    lambda x: 0 if x >= 0 else (x - rssi_min) / -rssi_min\n",
    ")\n",
    "df'''\n",
    "\n",
    "# Powered Normalization Using Dataset Minimum\n",
    "\n",
    "'''rssi_columns = df.columns[:raw_features]  # assuming RSSI is in the first raw_features columns\n",
    "\n",
    "# === Step 2: Replace 100 (no signal) with 0 ===\n",
    "df[rssi_columns] = df[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 3: Compute dataset-wide minimum RSSI (only for real signal values, excluding 0) ===\n",
    "rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "\n",
    "# === Step 4: Apply powered normalization (exclude 0 from normalization) ===\n",
    "gamma = 2  # you can change this exponent as needed\n",
    "\n",
    "df[rssi_columns] = df[rssi_columns].applymap(\n",
    "    lambda x: ((x - rssi_min) / -rssi_min) ** gamma if x < 0 else 0\n",
    ")\n",
    "\n",
    "df'''\n",
    "\n",
    "# Min-Max Normalization Using Global Min/Max\n",
    "\n",
    "'''# === Step 1: Select RSSI columns ===\n",
    "rssi_columns = df.columns[:raw_features]  # assuming RSSI is in the first `raw_features` columns\n",
    "\n",
    "# === Step 2: Replace 100 (no signal) with 0 ===\n",
    "df[rssi_columns] = df[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 3: Compute dataset-wide min and max RSSI values (excluding 0s) ===\n",
    "rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "rssi_max = df[rssi_columns][df[rssi_columns] < 0].max().max()\n",
    "\n",
    "# === Step 4: Apply Min-Max Normalization to [0, 1] (exclude 0 from normalization) ===\n",
    "df[rssi_columns] = df[rssi_columns].applymap(\n",
    "    lambda x: (x - rssi_min) / (rssi_max - rssi_min) if x < 0 else 0\n",
    ")\n",
    "\n",
    "df'''\n",
    "\n",
    "# Powered Transformation After Per-Fingerprint Normalization\n",
    "\n",
    "'''# === Step 1: Select RSSI columns ===\n",
    "rssi_columns = df.columns[:raw_features]  # assuming RSSI is in the first `raw_features` columns\n",
    "\n",
    "# === Step 2: Replace 100 (no signal) with 0 ===\n",
    "df[rssi_columns] = df[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 3: Convert RSSI to positive by shifting (only for non-zero values)\n",
    "rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "shift = rssi_min - 1\n",
    "\n",
    "# Shift only values less than 0, leave 0s unchanged\n",
    "df[rssi_columns] = df[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
    "\n",
    "# === Step 4: Per-row (fingerprint) normalization (excluding 0s) ===\n",
    "# Normalize each row based on the max of non-zero entries\n",
    "row_max = df[rssi_columns].replace(0, pd.NA).max(axis=1)\n",
    "\n",
    "df[rssi_columns] = df[rssi_columns].div(row_max, axis=0).fillna(0)\n",
    "\n",
    "# === Step 5: Apply powered transformation (e.g., square) only to non-zero values\n",
    "gamma = 2  # You can set this to any exponent like e, 1.5, etc.\n",
    "df[rssi_columns] = df[rssi_columns].applymap(lambda x: x**gamma if x > 0 else 0)'''\n",
    "\n",
    "# Sigmoid-Scaled Row Normalization\n",
    "\n",
    "# === Step 1: Select RSSI columns ===\n",
    "rssi_columns = df.columns[:raw_features] \n",
    "\n",
    "# === Step 2: Replace 100 (no signal) with 0 ===\n",
    "df[rssi_columns] = df[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 3: Shift RSSI to positive (only non-zero) ===\n",
    "rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "shift = rssi_min - 1  # shift negative RSSI to positive\n",
    "df[rssi_columns] = df[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
    "\n",
    "# === Step 4: Row-wise normalization (exclude zeros) ===\n",
    "row_max = df[rssi_columns].replace(0, pd.NA).max(axis=1)\n",
    "df[rssi_columns] = df[rssi_columns].div(row_max, axis=0).fillna(0)\n",
    "\n",
    "# === Step 5: Apply sigmoid transformation to non-zero values ===\n",
    "alpha = 10\n",
    "beta = 0.5\n",
    "df[rssi_columns] = df[rssi_columns].applymap(\n",
    "    lambda x: 1 / (1 + np.exp(-alpha * (x - beta))) if x > 0 else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced69441-05ca-4d87-a27b-b24a3cd7f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\AppData\\Local\\Temp\\ipykernel_6576\\2385938150.py:84: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  DT[rssi_columns] = DT[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
      "C:\\Users\\KMITL\\AppData\\Local\\Temp\\ipykernel_6576\\2385938150.py:93: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  DT[rssi_columns] = DT[rssi_columns].applymap(\n"
     ]
    }
   ],
   "source": [
    "# Linear Normalization to [0,1] Using Dataset Minimum\n",
    "\n",
    "'''# === Step 1: Replace 100 (no signal) with 0 ===\n",
    "DT[rssi_columns] = DT[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 2: Reuse the dataset-wide minimum RSSI value from training ===\n",
    "# Ensure `rssi_min` is defined from the training set beforehand\n",
    "# rssi_min = df[rssi_columns][df[rssi_columns] < 0].min().min()\n",
    "\n",
    "# === Step 3: Apply the linear normalization formula (excluding 0s) ===\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(\n",
    "    lambda x: 0 if x >= 0 else (x - rssi_min) / -rssi_min\n",
    ")\n",
    "DT'''\n",
    "\n",
    "# Powered Normalization Using Dataset Minimum\n",
    "\n",
    "'''# === Step 1: Replace 100 (no signal) with 0 ===\n",
    "DT[rssi_columns] = DT[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 2: Reuse the dataset-wide minimum RSSI value from training ===\n",
    "# Make sure `rssi_min` is defined and matches the one used during training:\n",
    "# Example:\n",
    "# rssi_min = -104\n",
    "\n",
    "# === Step 3: Apply powered normalization (exclude 0 from normalization) ===\n",
    "gamma = 2  # Power factor (can also use math.e or another value)\n",
    "\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(\n",
    "    lambda x: ((x - rssi_min) / -rssi_min) ** gamma if x < 0 else 0\n",
    ")\n",
    "\n",
    "DT'''\n",
    "\n",
    "# Min-Max Normalization Using Global Min/Max\n",
    "\n",
    "'''# === Step 1: Replace 100 (no signal) with 0 ===\n",
    "DT[rssi_columns] = DT[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 2: Reuse dataset-wide min and max RSSI values from training ===\n",
    "# Ensure rssi_min and rssi_max were saved during training:\n",
    "# Example:\n",
    "# rssi_min = -104\n",
    "# rssi_max = -30\n",
    "\n",
    "# === Step 3: Apply Min-Max Normalization to [0, 1] (exclude 0 from normalization) ===\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(\n",
    "    lambda x: (x - rssi_min) / (rssi_max - rssi_min) if x < 0 else 0\n",
    ")\n",
    "\n",
    "DT'''\n",
    "\n",
    "# Powered Transformation After Per-Fingerprint Normalization\n",
    "\n",
    "'''# === Step 1: Replace 100 (no signal) with 0 ===\n",
    "DT[rssi_columns] = DT[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 2: Reuse dataset-wide minimum RSSI value from training to shift into positive range\n",
    "# Make sure `rssi_min` is defined (e.g., rssi_min = -104)\n",
    "shift = rssi_min - 1\n",
    "\n",
    "# Shift only real RSSI values (< 0), leave 0s untouched\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
    "\n",
    "# === Step 3: Normalize each fingerprint row-wise to [0, 1], excluding 0s ===\n",
    "row_max = DT[rssi_columns].replace(0, pd.NA).max(axis=1)\n",
    "DT[rssi_columns] = DT[rssi_columns].div(row_max, axis=0).fillna(0)\n",
    "\n",
    "# === Step 4: Apply powered transformation only to non-zero values ===\n",
    "#gamma = 2  # You can adjust this exponent as needed\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(lambda x: x**gamma if x > 0 else 0)\n",
    "\n",
    "DT'''\n",
    "\n",
    "# Sigmoid-Scaled Row Normalization\n",
    "\n",
    "\n",
    "# === Step 1: Replace 100 (no signal) with 0 ===\n",
    "DT[rssi_columns] = DT[rssi_columns].replace(100, 0)\n",
    "\n",
    "# === Step 2: Shift RSSI using dataset-wide min (from training) ===\n",
    "shift = rssi_min - 1\n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(lambda x: x - shift if x < 0 else 0)\n",
    "\n",
    "# === Step 3: Row-wise normalization (exclude zeros) ===\n",
    "row_max = DT[rssi_columns].replace(0, np.nan).max(axis=1)\n",
    "DT[rssi_columns] = DT[rssi_columns].div(row_max, axis=0).fillna(0)\n",
    "\n",
    "# === Step 4: Apply sigmoid transformation ===\n",
    "alpha = 10\n",
    "beta = 0.5 \n",
    "DT[rssi_columns] = DT[rssi_columns].applymap(\n",
    "    lambda x: 1 / (1 + np.exp(-alpha * (x - beta))) if x > 0 else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8896c3-02c6-4c0a-bee9-b72a8979603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:raw_features]\n",
    "X_target = DT.iloc[:,:raw_features]\n",
    "\n",
    "y_floor = df.iloc[:, -1]\n",
    "y_coordinate = df.iloc[:, [-3,-2]]\n",
    "y_target_floor = DT.iloc[:,-1]\n",
    "y_target_coordinate = DT.iloc[:, [-3,-2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f72d0-07f0-479a-9829-1e50082ddf64",
   "metadata": {},
   "source": [
    "# Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28eaa4f-9ec5-427f-b020-563bf8967b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\KMITL\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Confidence weighting using Pearson correlation\n",
    "\n",
    "# Step 6.1: Compute Pearson correlations between each feature and target\n",
    "correlations = X.apply(lambda x: x.corr(y_floor), axis=0)\n",
    "\n",
    "# Step 6.2: Replace NaN with 0\n",
    "correlations = correlations.fillna(0)\n",
    "\n",
    "# Step 6.3: Compute confidence weights\n",
    "confidence_weights = correlations.abs()\n",
    "\n",
    "# Optional: scale weights to [0, 1]\n",
    "confidence_weights = confidence_weights / confidence_weights.max()\n",
    "\n",
    "# Step 6.4: Multiply each feature by its confidence weight\n",
    "X_weighted = X.mul(confidence_weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5e9f86-3034-43bd-bf17-5ccab00382b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rss1</th>\n",
       "      <th>rss2</th>\n",
       "      <th>rss4</th>\n",
       "      <th>rss6</th>\n",
       "      <th>rss7</th>\n",
       "      <th>rss8</th>\n",
       "      <th>rss9</th>\n",
       "      <th>rss10</th>\n",
       "      <th>rss11</th>\n",
       "      <th>rss12</th>\n",
       "      <th>...</th>\n",
       "      <th>rss978</th>\n",
       "      <th>rss979</th>\n",
       "      <th>rss980</th>\n",
       "      <th>rss981</th>\n",
       "      <th>rss983</th>\n",
       "      <th>rss986</th>\n",
       "      <th>rss988</th>\n",
       "      <th>rss989</th>\n",
       "      <th>rss991</th>\n",
       "      <th>rss992</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205481</td>\n",
       "      <td>0.08294</td>\n",
       "      <td>0.221649</td>\n",
       "      <td>0.078122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rss1  rss2      rss4  rss6  rss7      rss8     rss9     rss10     rss11  \\\n",
       "0     0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "1     0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "2     0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "3     0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "4     0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "..    ...   ...       ...   ...   ...       ...      ...       ...       ...   \n",
       "692   0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "693   0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "694   0.0   0.0  0.000000   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "695   0.0   0.0  0.000000   0.0   0.0  0.205481  0.08294  0.221649  0.078122   \n",
       "696   0.0   0.0  0.018147   0.0   0.0  0.000000  0.00000  0.000000  0.000000   \n",
       "\n",
       "     rss12  ...  rss978  rss979    rss980  rss981  rss983  rss986  rss988  \\\n",
       "0      0.0  ...     0.0     0.0  0.127680     0.0     0.0     0.0     0.0   \n",
       "1      0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "2      0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "3      0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "4      0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "..     ...  ...     ...     ...       ...     ...     ...     ...     ...   \n",
       "692    0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "693    0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "694    0.0  ...     0.0     0.0  0.008991     0.0     0.0     0.0     0.0   \n",
       "695    0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "696    0.0  ...     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     rss989  rss991  rss992  \n",
       "0       0.0     0.0     0.0  \n",
       "1       0.0     0.0     0.0  \n",
       "2       0.0     0.0     0.0  \n",
       "3       0.0     0.0     0.0  \n",
       "4       0.0     0.0     0.0  \n",
       "..      ...     ...     ...  \n",
       "692     0.0     0.0     0.0  \n",
       "693     0.0     0.0     0.0  \n",
       "694     0.0     0.0     0.0  \n",
       "695     0.0     0.0     0.0  \n",
       "696     0.0     0.0     0.0  \n",
       "\n",
       "[697 rows x 779 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confidence weighting using Pearson correlation\n",
    "\n",
    "# Step 6.5: Remove all-zero columns\n",
    "X_weighted_cleaned = X_weighted.loc[:, (X_weighted != 0).any(axis=0)]\n",
    "\n",
    "# Step 6.6: Update feature count\n",
    "raw_features = X_weighted_cleaned.shape[1]\n",
    "\n",
    "# Result: X_weighted_cleaned has transformed, normalized, and confidence-weighted features\n",
    "X_weighted_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4078cfb-2bbb-4844-88b6-3538ca792d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rss1</th>\n",
       "      <th>rss2</th>\n",
       "      <th>rss4</th>\n",
       "      <th>rss6</th>\n",
       "      <th>rss7</th>\n",
       "      <th>rss8</th>\n",
       "      <th>rss9</th>\n",
       "      <th>rss10</th>\n",
       "      <th>rss11</th>\n",
       "      <th>rss12</th>\n",
       "      <th>...</th>\n",
       "      <th>rss978</th>\n",
       "      <th>rss979</th>\n",
       "      <th>rss980</th>\n",
       "      <th>rss981</th>\n",
       "      <th>rss983</th>\n",
       "      <th>rss986</th>\n",
       "      <th>rss988</th>\n",
       "      <th>rss989</th>\n",
       "      <th>rss991</th>\n",
       "      <th>rss992</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3951 rows × 779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rss1  rss2  rss4  rss6  rss7     rss8  rss9     rss10  rss11  rss12  \\\n",
       "0      0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "1      0.0   0.0   0.0   0.0   0.0  0.22271   0.0  0.214504    0.0    0.0   \n",
       "2      0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "3      0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "4      0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "...    ...   ...   ...   ...   ...      ...   ...       ...    ...    ...   \n",
       "3946   0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "3947   0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "3948   0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "3949   0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "3950   0.0   0.0   0.0   0.0   0.0  0.00000   0.0  0.000000    0.0    0.0   \n",
       "\n",
       "      ...  rss978  rss979  rss980  rss981  rss983    rss986  rss988  rss989  \\\n",
       "0     ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "1     ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "2     ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "3     ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "4     ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "...   ...     ...     ...     ...     ...     ...       ...     ...     ...   \n",
       "3946  ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "3947  ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "3948  ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "3949  ...     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0   \n",
       "3950  ...     0.0     0.0     0.0     0.0     0.0  0.058033     0.0     0.0   \n",
       "\n",
       "      rss991  rss992  \n",
       "0        0.0     0.0  \n",
       "1        0.0     0.0  \n",
       "2        0.0     0.0  \n",
       "3        0.0     0.0  \n",
       "4        0.0     0.0  \n",
       "...      ...     ...  \n",
       "3946     0.0     0.0  \n",
       "3947     0.0     0.0  \n",
       "3948     0.0     0.0  \n",
       "3949     0.0     0.0  \n",
       "3950     0.0     0.0  \n",
       "\n",
       "[3951 rows x 779 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confidence weighting using Pearson correlation\n",
    "\n",
    "# Step 2: Apply the same weights to X_target\n",
    "X_target_weighted = X_target.mul(confidence_weights, axis=1)\n",
    "\n",
    "# Step 3: Keep only the columns that were kept in training\n",
    "X_target_weighted_cleaned = X_target_weighted[X_weighted_cleaned.columns]\n",
    "\n",
    "X_target_weighted_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e8a154-9cda-4fe0-afc6-4f8da04c1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_weighted_cleaned\n",
    "X_target = X_target_weighted_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9e967e-3a8f-4e51-a1da-c72574b685a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "#raw_features = 992\n",
    "#df = pd.read_excel('2. Dataset Tampere.xlsx')\n",
    "#X = df.iloc[:, :raw_features]\n",
    "\n",
    "# Flatten all values into a single array\n",
    "all_values = X.values.flatten()\n",
    "\n",
    "# Remove NaNs and values equal to 100\n",
    "all_values = all_values[~pd.isnull(all_values)]\n",
    "all_values = all_values[all_values != 0]  # <-- Exclude 100\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Histogram\n",
    "ax.hist(all_values, bins=80, color='lightcoral', edgecolor='black', zorder=1)\n",
    "\n",
    "# Grid behind\n",
    "ax.grid(True, linestyle='--', linewidth=0.6, zorder=1)\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\"Tampere\", fontsize=24)\n",
    "ax.set_xlabel(\"Transformed RSS\", fontsize=20)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=20)\n",
    "\n",
    "# Adjust tick font sizes\n",
    "ax.tick_params(axis='both', labelsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Transformed Tampere distribution.svg', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc305bd8-e3c8-4c59-91e5-b4d7d3ef535a",
   "metadata": {},
   "source": [
    "# Floor Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ce25ef-42ee-4a0b-8e58-c82c95fc066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import random\n",
    "import numpy as np\n",
    "from optuna.exceptions import TrialPruned\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f69fa6-a4ae-41b5-a505-7e96fca93eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train-test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_floor, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Fix random seeds for reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00baab73-6f2a-4887-b61f-9958bc38d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_time1 = time.time()\n",
    "\n",
    "# --- Custom weight function for KNN ---\n",
    "def knn_weight(d):\n",
    "    return 1 / (d + 1e-6) ** 2\n",
    "\n",
    "\n",
    "# --- Objective function for KNN ---\n",
    "def objective_wknn(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "    p = trial.suggest_int('p', 1, 5)\n",
    "    metric = trial.suggest_categorical('metric', ['minkowski', 'euclidean', 'manhattan'])\n",
    "\n",
    "    knn = KNeighborsClassifier(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=knn_weight,\n",
    "        p=p,\n",
    "        metric=metric\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        knn.fit(X_tr, y_tr)\n",
    "        y_pred = knn.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- Objective function for RandomForest ---\n",
    "def objective_rf(trial):\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=trial.suggest_categorical('max_depth', [None] + list(range(5, 51))),\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 500),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        max_features=trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- Objective function for LightGBM ---\n",
    "def objective_lgb(trial):\n",
    "    param = {\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(np.unique(y_train)),\n",
    "        'random_state': SEED,\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='multi_error',\n",
    "            callbacks=[lgb.early_stopping(100)]\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- Objective function for XGBoost ---\n",
    "def objective_xgb(trial):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "        min_child_weight=trial.suggest_float('min_child_weight', 1, 10),\n",
    "        gamma=trial.suggest_float('gamma', 0, 5),\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- Objective function for GaussianNB ---\n",
    "def objective_gnb(trial):\n",
    "    model = GaussianNB(\n",
    "        var_smoothing=trial.suggest_float('var_smoothing', 1e-12, 1e-6, log=True)\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- Objective function for AdaBoost ---\n",
    "def objective_adaboost(trial):\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        criterion=trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        max_depth=trial.suggest_int('max_depth', 1, 10),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    model = AdaBoostClassifier(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef916e8-fbe2-46ab-a21f-4bc26827d203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 12:45:30,088] A new study created in memory with name: no-name-338be68d-4304-4a3f-9e00-78306d1f43b2\n",
      "[I 2025-12-20 12:45:34,940] Trial 0 finished with value: 0.8329954954954955 and parameters: {'n_neighbors': 41, 'p': 5, 'metric': 'euclidean'}. Best is trial 0 with value: 0.8329954954954955.\n",
      "[I 2025-12-20 12:45:37,724] Trial 1 finished with value: 0.8366312741312741 and parameters: {'n_neighbors': 29, 'p': 5, 'metric': 'euclidean'}. Best is trial 1 with value: 0.8366312741312741.\n",
      "[I 2025-12-20 12:45:40,244] Trial 2 finished with value: 0.8886743886743886 and parameters: {'n_neighbors': 15, 'p': 4, 'metric': 'manhattan'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:43,853] Trial 3 finished with value: 0.8527348777348778 and parameters: {'n_neighbors': 14, 'p': 3, 'metric': 'minkowski'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:46,572] Trial 4 finished with value: 0.8743243243243242 and parameters: {'n_neighbors': 25, 'p': 3, 'metric': 'manhattan'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:49,310] Trial 5 finished with value: 0.8886261261261261 and parameters: {'n_neighbors': 5, 'p': 4, 'metric': 'manhattan'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:52,350] Trial 6 finished with value: 0.8851029601029602 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'euclidean'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:55,296] Trial 7 finished with value: 0.8886422136422137 and parameters: {'n_neighbors': 2, 'p': 3, 'metric': 'euclidean'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:45:57,886] Trial 8 finished with value: 0.8312258687258687 and parameters: {'n_neighbors': 35, 'p': 2, 'metric': 'euclidean'}. Best is trial 2 with value: 0.8886743886743886.\n",
      "[I 2025-12-20 12:46:00,715] Trial 9 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:03,425] Trial 10 finished with value: 0.856354568854569 and parameters: {'n_neighbors': 50, 'p': 1, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:06,030] Trial 11 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 16, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:08,592] Trial 12 finished with value: 0.8922619047619047 and parameters: {'n_neighbors': 13, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:11,118] Trial 13 finished with value: 0.8922619047619047 and parameters: {'n_neighbors': 10, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:14,799] Trial 14 finished with value: 0.8779118404118404 and parameters: {'n_neighbors': 23, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:17,551] Trial 15 finished with value: 0.8904761904761905 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:20,391] Trial 16 finished with value: 0.8761100386100387 and parameters: {'n_neighbors': 22, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:23,121] Trial 17 finished with value: 0.8833333333333332 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:26,164] Trial 18 finished with value: 0.8796975546975545 and parameters: {'n_neighbors': 18, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:28,625] Trial 19 finished with value: 0.881483268983269 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:31,458] Trial 20 finished with value: 0.8491795366795367 and parameters: {'n_neighbors': 19, 'p': 2, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:34,667] Trial 21 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:37,185] Trial 22 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:39,688] Trial 23 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:42,594] Trial 24 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:45,223] Trial 25 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:47,847] Trial 26 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:50,263] Trial 27 finished with value: 0.881483268983269 and parameters: {'n_neighbors': 30, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:54,034] Trial 28 finished with value: 0.8706885456885457 and parameters: {'n_neighbors': 5, 'p': 4, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:56,995] Trial 29 finished with value: 0.881483268983269 and parameters: {'n_neighbors': 11, 'p': 5, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:46:59,406] Trial 30 finished with value: 0.8347972972972973 and parameters: {'n_neighbors': 39, 'p': 1, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:02,036] Trial 31 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:05,036] Trial 32 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:07,630] Trial 33 finished with value: 0.8886261261261261 and parameters: {'n_neighbors': 5, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:10,487] Trial 34 finished with value: 0.8833333333333332 and parameters: {'n_neighbors': 8, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:13,070] Trial 35 finished with value: 0.8868725868725867 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:15,333] Trial 36 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:18,064] Trial 37 finished with value: 0.8293758043758043 and parameters: {'n_neighbors': 48, 'p': 5, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:20,754] Trial 38 finished with value: 0.8886743886743886 and parameters: {'n_neighbors': 15, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:24,661] Trial 39 finished with value: 0.8652831402831402 and parameters: {'n_neighbors': 4, 'p': 4, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:27,333] Trial 40 finished with value: 0.8348133848133849 and parameters: {'n_neighbors': 28, 'p': 5, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:29,997] Trial 41 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:32,694] Trial 42 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:36,038] Trial 43 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:38,949] Trial 44 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:41,930] Trial 45 finished with value: 0.8922619047619047 and parameters: {'n_neighbors': 10, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:44,661] Trial 46 finished with value: 0.8922619047619047 and parameters: {'n_neighbors': 13, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:47,603] Trial 47 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:50,447] Trial 48 finished with value: 0.8833011583011583 and parameters: {'n_neighbors': 9, 'p': 4, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:53,064] Trial 49 finished with value: 0.8832850707850708 and parameters: {'n_neighbors': 17, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:55,315] Trial 50 finished with value: 0.8778796653796652 and parameters: {'n_neighbors': 20, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:57,241] Trial 51 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:47:59,061] Trial 52 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:02,236] Trial 53 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:05,053] Trial 54 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:09,231] Trial 55 finished with value: 0.8742760617760619 and parameters: {'n_neighbors': 5, 'p': 3, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:11,793] Trial 56 finished with value: 0.8904761904761905 and parameters: {'n_neighbors': 9, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:14,767] Trial 57 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:17,533] Trial 58 finished with value: 0.8886743886743886 and parameters: {'n_neighbors': 14, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:20,015] Trial 59 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:22,724] Trial 60 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:25,425] Trial 61 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:28,187] Trial 62 finished with value: 0.8833333333333332 and parameters: {'n_neighbors': 8, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:30,702] Trial 63 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:33,028] Trial 64 finished with value: 0.881483268983269 and parameters: {'n_neighbors': 11, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:37,608] Trial 65 finished with value: 0.8742760617760619 and parameters: {'n_neighbors': 5, 'p': 3, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:40,305] Trial 66 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 2, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:43,077] Trial 67 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:45,586] Trial 68 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:47,941] Trial 69 finished with value: 0.8312258687258687 and parameters: {'n_neighbors': 35, 'p': 1, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:50,477] Trial 70 finished with value: 0.8922619047619047 and parameters: {'n_neighbors': 10, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:53,442] Trial 71 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 2, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:56,367] Trial 72 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:48:59,581] Trial 73 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:01,754] Trial 74 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:04,356] Trial 75 finished with value: 0.8833333333333332 and parameters: {'n_neighbors': 8, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:07,541] Trial 76 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 2, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:10,155] Trial 77 finished with value: 0.8886261261261261 and parameters: {'n_neighbors': 5, 'p': 5, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:14,100] Trial 78 finished with value: 0.8455276705276704 and parameters: {'n_neighbors': 12, 'p': 4, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:17,181] Trial 79 finished with value: 0.8617438867438867 and parameters: {'n_neighbors': 44, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:20,138] Trial 80 finished with value: 0.8886422136422137 and parameters: {'n_neighbors': 1, 'p': 2, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:23,210] Trial 81 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:25,752] Trial 82 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:28,477] Trial 83 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:31,089] Trial 84 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:34,094] Trial 85 finished with value: 0.8833333333333332 and parameters: {'n_neighbors': 8, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:37,109] Trial 86 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 2, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:39,407] Trial 87 finished with value: 0.8904761904761905 and parameters: {'n_neighbors': 9, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:42,179] Trial 88 finished with value: 0.8725225225225225 and parameters: {'n_neighbors': 24, 'p': 2, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:45,004] Trial 89 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:47,460] Trial 90 finished with value: 0.8796814671814672 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:49,927] Trial 91 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:52,475] Trial 92 finished with value: 0.8886261261261261 and parameters: {'n_neighbors': 5, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:55,302] Trial 93 finished with value: 0.9012226512226512 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:49:57,979] Trial 94 finished with value: 0.8922940797940798 and parameters: {'n_neighbors': 1, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:50:00,420] Trial 95 finished with value: 0.897635135135135 and parameters: {'n_neighbors': 3, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:50:03,407] Trial 96 finished with value: 0.8850707850707851 and parameters: {'n_neighbors': 7, 'p': 4, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:50:07,842] Trial 97 finished with value: 0.8634491634491634 and parameters: {'n_neighbors': 2, 'p': 3, 'metric': 'minkowski'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:50:10,593] Trial 98 finished with value: 0.8886261261261261 and parameters: {'n_neighbors': 5, 'p': 3, 'metric': 'manhattan'}. Best is trial 9 with value: 0.9012226512226512.\n",
      "[I 2025-12-20 12:50:13,683] Trial 99 finished with value: 0.8833011583011583 and parameters: {'n_neighbors': 9, 'p': 2, 'metric': 'euclidean'}. Best is trial 9 with value: 0.9012226512226512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN hyperparameters: {'n_neighbors': 4, 'p': 1, 'metric': 'manhattan'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 12:50:19,093] A new study created in memory with name: no-name-627fc659-8d6d-449a-93b3-1969ef1264e4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross-val Accuracies: [0.96428571 0.85714286 0.98214286 0.94642857 0.89285714 0.875\n",
      " 0.91071429 0.85454545 0.90909091 0.81818182]\n",
      "KNN Mean CV Accuracy: 0.9010389610389609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 12:50:29,013] Trial 0 finished with value: 0.7629504504504505 and parameters: {'max_depth': 5, 'n_estimators': 197, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.7629504504504505.\n",
      "[I 2025-12-20 12:50:39,147] Trial 1 finished with value: 0.8599099099099099 and parameters: {'max_depth': 44, 'n_estimators': 329, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.8599099099099099.\n",
      "[I 2025-12-20 12:50:47,866] Trial 2 finished with value: 0.8312419562419562 and parameters: {'max_depth': 34, 'n_estimators': 95, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 1 with value: 0.8599099099099099.\n",
      "[I 2025-12-20 12:51:02,191] Trial 3 finished with value: 0.820447232947233 and parameters: {'max_depth': 45, 'n_estimators': 485, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 1 with value: 0.8599099099099099.\n",
      "[I 2025-12-20 12:51:12,326] Trial 4 finished with value: 0.8706563706563706 and parameters: {'max_depth': 14, 'n_estimators': 283, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.8706563706563706.\n",
      "[I 2025-12-20 12:51:22,939] Trial 5 finished with value: 0.8330115830115832 and parameters: {'max_depth': 41, 'n_estimators': 220, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 4 with value: 0.8706563706563706.\n",
      "[I 2025-12-20 12:51:33,089] Trial 6 finished with value: 0.8221685971685971 and parameters: {'max_depth': 42, 'n_estimators': 321, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.8706563706563706.\n",
      "[I 2025-12-20 12:51:41,941] Trial 7 finished with value: 0.8994047619047618 and parameters: {'max_depth': 47, 'n_estimators': 109, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 7 with value: 0.8994047619047618.\n",
      "[I 2025-12-20 12:51:52,816] Trial 8 finished with value: 0.8024292149292149 and parameters: {'max_depth': 43, 'n_estimators': 423, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 7 with value: 0.8994047619047618.\n",
      "[I 2025-12-20 12:52:04,341] Trial 9 finished with value: 0.8598938223938223 and parameters: {'max_depth': 36, 'n_estimators': 442, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 7 with value: 0.8994047619047618.\n",
      "[I 2025-12-20 12:52:11,115] Trial 10 finished with value: 0.9191280566280566 and parameters: {'max_depth': 47, 'n_estimators': 68, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:18,420] Trial 11 finished with value: 0.8994047619047618 and parameters: {'max_depth': 47, 'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:27,206] Trial 12 finished with value: 0.9155888030888031 and parameters: {'max_depth': 47, 'n_estimators': 139, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:35,637] Trial 13 finished with value: 0.8922458172458173 and parameters: {'max_depth': 23, 'n_estimators': 163, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:43,463] Trial 14 finished with value: 0.88503861003861 and parameters: {'max_depth': 33, 'n_estimators': 137, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:50,895] Trial 15 finished with value: 0.8562902187902187 and parameters: {'max_depth': 16, 'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:52:59,700] Trial 16 finished with value: 0.8670688545688545 and parameters: {'max_depth': None, 'n_estimators': 224, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:08,934] Trial 17 finished with value: 0.9047619047619048 and parameters: {'max_depth': 19, 'n_estimators': 164, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:17,737] Trial 18 finished with value: 0.8814350064350064 and parameters: {'max_depth': 15, 'n_estimators': 90, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:28,837] Trial 19 finished with value: 0.8384330759330758 and parameters: {'max_depth': 8, 'n_estimators': 251, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:37,548] Trial 20 finished with value: 0.8472651222651223 and parameters: {'max_depth': 37, 'n_estimators': 142, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:46,248] Trial 21 finished with value: 0.9065958815958816 and parameters: {'max_depth': 20, 'n_estimators': 176, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:53:53,011] Trial 22 finished with value: 0.8886743886743886 and parameters: {'max_depth': 20, 'n_estimators': 110, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:01,572] Trial 23 finished with value: 0.881515444015444 and parameters: {'max_depth': 47, 'n_estimators': 189, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:09,049] Trial 24 finished with value: 0.8975868725868725 and parameters: {'max_depth': 20, 'n_estimators': 75, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:17,066] Trial 25 finished with value: 0.865299227799228 and parameters: {'max_depth': 24, 'n_estimators': 133, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:23,316] Trial 26 finished with value: 0.8868564993564994 and parameters: {'max_depth': 31, 'n_estimators': 282, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:26,403] Trial 27 finished with value: 0.8670688545688545 and parameters: {'max_depth': 46, 'n_estimators': 181, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:29,950] Trial 28 finished with value: 0.8868564993564994 and parameters: {'max_depth': 12, 'n_estimators': 241, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:33,189] Trial 29 finished with value: 0.8132561132561132 and parameters: {'max_depth': 50, 'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:34,730] Trial 30 finished with value: 0.8328989703989704 and parameters: {'max_depth': 40, 'n_estimators': 75, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:37,470] Trial 31 finished with value: 0.9047619047619048 and parameters: {'max_depth': 19, 'n_estimators': 164, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:39,775] Trial 32 finished with value: 0.881451093951094 and parameters: {'max_depth': 28, 'n_estimators': 139, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:41,751] Trial 33 finished with value: 0.9137709137709138 and parameters: {'max_depth': 49, 'n_estimators': 117, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:44,065] Trial 34 finished with value: 0.8634974259974261 and parameters: {'max_depth': 49, 'n_estimators': 124, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:45,560] Trial 35 finished with value: 0.8563706563706563 and parameters: {'max_depth': 9, 'n_estimators': 88, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:51,610] Trial 36 finished with value: 0.8832528957528958 and parameters: {'max_depth': 25, 'n_estimators': 326, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:53,718] Trial 37 finished with value: 0.9048101673101673 and parameters: {'max_depth': 17, 'n_estimators': 105, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:54:56,502] Trial 38 finished with value: 0.87247425997426 and parameters: {'max_depth': 39, 'n_estimators': 209, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:02,999] Trial 39 finished with value: 0.8474259974259972 and parameters: {'max_depth': 11, 'n_estimators': 356, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:04,508] Trial 40 finished with value: 0.8742921492921493 and parameters: {'max_depth': 48, 'n_estimators': 70, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:06,233] Trial 41 finished with value: 0.9047940797940799 and parameters: {'max_depth': 17, 'n_estimators': 103, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:08,516] Trial 42 finished with value: 0.9101673101673102 and parameters: {'max_depth': 30, 'n_estimators': 120, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:10,852] Trial 43 finished with value: 0.9101351351351351 and parameters: {'max_depth': 30, 'n_estimators': 163, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:12,701] Trial 44 finished with value: 0.8796975546975547 and parameters: {'max_depth': 21, 'n_estimators': 119, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:15,331] Trial 45 finished with value: 0.915556628056628 and parameters: {'max_depth': 30, 'n_estimators': 156, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:16,731] Trial 46 finished with value: 0.8742760617760619 and parameters: {'max_depth': 30, 'n_estimators': 59, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:18,965] Trial 47 finished with value: 0.917326254826255 and parameters: {'max_depth': 22, 'n_estimators': 149, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9191280566280566.\n",
      "[I 2025-12-20 12:55:21,601] Trial 48 finished with value: 0.8652509652509653 and parameters: {'max_depth': 29, 'n_estimators': 147, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 10 with value: 0.9191280566280566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest hyperparameters: {'max_depth': 47, 'n_estimators': 68, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Cross-val Accuracies: [0.96428571 0.92857143 0.91071429 0.92857143 0.91071429 0.89285714\n",
      " 0.875      0.90909091 0.96363636 0.8       ]\n",
      "RF Mean CV Accuracy: 0.9083441558441558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_floor_pred_UJI.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "# --- Run the optimization ---\n",
    "study1 = optuna.create_study(direction='maximize')\n",
    "study1.optimize(objective_wknn, n_trials=100, timeout=300)\n",
    "\n",
    "# --- Get best parameters ---\n",
    "best_params1 = study1.best_params\n",
    "print(\"Best KNN hyperparameters:\", best_params1)\n",
    "\n",
    "# --- Train final model ---\n",
    "knn_floor_final = KNeighborsClassifier(\n",
    "    n_neighbors=best_params1['n_neighbors'],\n",
    "    weights=knn_weight,\n",
    "    p=best_params1['p'],\n",
    "    metric=best_params1['metric']\n",
    ")\n",
    "\n",
    "# --- Cross-validation accuracy ---\n",
    "cv_scores_knn = cross_val_score(knn_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"KNN Cross-val Accuracies:\", cv_scores_knn)\n",
    "print(\"KNN Mean CV Accuracy:\", cv_scores_knn.mean())\n",
    "\n",
    "# --- Train on full training set ---\n",
    "knn_floor_final.fit(X_train, y_train)\n",
    "joblib.dump(knn_floor_final, 'knn_floor_Tampere.joblib')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "# --- Run the optimization ---\n",
    "study2 = optuna.create_study(direction='maximize')\n",
    "study2.optimize(objective_rf, n_trials=100, timeout=300)\n",
    "\n",
    "# --- Train final model with best hyperparameters ---\n",
    "best_params2 = study2.best_params\n",
    "print(\"Best Random Forest hyperparameters:\", best_params2)\n",
    "\n",
    "rf_floor_final = RandomForestClassifier(\n",
    "    **best_params2,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Cross-validation accuracy ---\n",
    "cv_scores_rf = cross_val_score(rf_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"RF Cross-val Accuracies:\", cv_scores_rf)\n",
    "print(\"RF Mean CV Accuracy:\", cv_scores_rf.mean())\n",
    "\n",
    "# --- Train on full training set ---\n",
    "rf_floor_final.fit(X_train, y_train)\n",
    "joblib.dump(rf_floor_final, 'rf_floor_pred_Tampere.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa97c495-73ec-4fa5-9a54-482f027a74a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 12:55:50,025] A new study created in memory with name: no-name-fc5e9d39-2267-4114-8c89-a1772abdb4cd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's multi_error: 0.1875\tvalid_0's multi_logloss: 0.488501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_error: 0.196429\tvalid_0's multi_logloss: 0.678973\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's multi_error: 0.198198\tvalid_0's multi_logloss: 0.549958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_error: 0.279279\tvalid_0's multi_logloss: 0.80189\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:03:03,688] Trial 0 finished with value: 0.7718629343629344 and parameters: {'learning_rate': 0.025665047234812447, 'num_leaves': 24, 'max_depth': 4, 'min_child_samples': 75}. Best is trial 0 with value: 0.7718629343629344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_error: 0.279279\tvalid_0's multi_logloss: 0.695577\n",
      "Best LightGBM hyperparameters: {'learning_rate': 0.025665047234812447, 'num_leaves': 24, 'max_depth': 4, 'min_child_samples': 75}\n",
      "LGB Cross-val Accuracies: [0.875      0.85714286 0.80357143 0.80357143 0.76785714 0.73214286\n",
      " 0.69642857 0.72727273 0.81818182 0.76363636]\n",
      "LGB Mean CV Accuracy: 0.7844805194805196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lgb_floor_pred_UJI.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Optuna study\n",
    "study3 = optuna.create_study(direction='maximize')\n",
    "study3.optimize(objective_lgb, n_trials=100, timeout=300)\n",
    "\n",
    "# Best params\n",
    "best_params3 = study3.best_params\n",
    "print(\"Best LightGBM hyperparameters:\", best_params3)\n",
    "\n",
    "best_params3.update({\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train))\n",
    "})\n",
    "\n",
    "# Final model\n",
    "lgb_floor_final = lgb.LGBMClassifier(**best_params3)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_lgb = cross_val_score(lgb_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"LGB Cross-val Accuracies:\", cv_scores_lgb)\n",
    "print(\"LGB Mean CV Accuracy:\", cv_scores_lgb.mean())\n",
    "\n",
    "# Train final model\n",
    "lgb_floor_final.fit(X_train, y_train)\n",
    "\n",
    "# Save\n",
    "joblib.dump(lgb_floor_final, 'lgb_floor_pred_Tampere.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f566bffb-9d89-45be-ad21-8e8700d79ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:03:08,708] A new study created in memory with name: no-name-170cbb0e-027f-4846-b2ce-9c8f7c77bfe9\n",
      "[I 2025-12-20 13:03:13,951] Trial 0 finished with value: 0.8454954954954955 and parameters: {'n_estimators': 93, 'learning_rate': 0.16725272494881377, 'max_depth': 4, 'min_child_weight': 4.2465276527104, 'gamma': 2.9224827500954915, 'subsample': 0.8250884107969028, 'colsample_bytree': 0.9804998449622011}. Best is trial 0 with value: 0.8454954954954955.\n",
      "[I 2025-12-20 13:03:23,090] Trial 1 finished with value: 0.8598938223938225 and parameters: {'n_estimators': 147, 'learning_rate': 0.03536338871861502, 'max_depth': 5, 'min_child_weight': 5.305426501366411, 'gamma': 2.1777074375958034, 'subsample': 0.9594488033819276, 'colsample_bytree': 0.547250043080747}. Best is trial 1 with value: 0.8598938223938225.\n",
      "[I 2025-12-20 13:03:29,388] Trial 2 finished with value: 0.8365508365508367 and parameters: {'n_estimators': 91, 'learning_rate': 0.05264416757005118, 'max_depth': 4, 'min_child_weight': 9.17008658052785, 'gamma': 0.8936051133068995, 'subsample': 0.6167870162478706, 'colsample_bytree': 0.9170774450396346}. Best is trial 1 with value: 0.8598938223938225.\n",
      "[I 2025-12-20 13:04:07,401] Trial 3 finished with value: 0.8364864864864865 and parameters: {'n_estimators': 182, 'learning_rate': 0.0775820571892324, 'max_depth': 5, 'min_child_weight': 4.596065394090219, 'gamma': 4.337419942815124, 'subsample': 0.7003826974382372, 'colsample_bytree': 0.9506061963962551}. Best is trial 1 with value: 0.8598938223938225.\n",
      "[I 2025-12-20 13:04:36,173] Trial 4 finished with value: 0.8437258687258687 and parameters: {'n_estimators': 151, 'learning_rate': 0.4910979795626967, 'max_depth': 10, 'min_child_weight': 3.6947783111148764, 'gamma': 4.005796785047871, 'subsample': 0.9645316682287068, 'colsample_bytree': 0.9561658638541317}. Best is trial 1 with value: 0.8598938223938225.\n",
      "[I 2025-12-20 13:04:54,348] Trial 5 finished with value: 0.850900900900901 and parameters: {'n_estimators': 120, 'learning_rate': 0.2913467641496429, 'max_depth': 5, 'min_child_weight': 5.539328331337159, 'gamma': 3.115175158654196, 'subsample': 0.9137656496316767, 'colsample_bytree': 0.8247295039712609}. Best is trial 1 with value: 0.8598938223938225.\n",
      "[I 2025-12-20 13:05:13,860] Trial 6 finished with value: 0.8616956241956242 and parameters: {'n_estimators': 137, 'learning_rate': 0.021893882336618153, 'max_depth': 9, 'min_child_weight': 2.7877175229681797, 'gamma': 3.5389552999164096, 'subsample': 0.7068542837952079, 'colsample_bytree': 0.5256284361571752}. Best is trial 6 with value: 0.8616956241956242.\n",
      "[I 2025-12-20 13:05:26,498] Trial 7 finished with value: 0.8491634491634492 and parameters: {'n_estimators': 158, 'learning_rate': 0.47256395042147603, 'max_depth': 4, 'min_child_weight': 2.827210333345839, 'gamma': 3.392950338770813, 'subsample': 0.8251341963003388, 'colsample_bytree': 0.5908638673067688}. Best is trial 6 with value: 0.8616956241956242.\n",
      "[I 2025-12-20 13:05:34,635] Trial 8 finished with value: 0.8490347490347491 and parameters: {'n_estimators': 77, 'learning_rate': 0.28943649204107974, 'max_depth': 8, 'min_child_weight': 9.544940666645148, 'gamma': 2.0164593665882076, 'subsample': 0.6008425920930545, 'colsample_bytree': 0.5880877244690426}. Best is trial 6 with value: 0.8616956241956242.\n",
      "[I 2025-12-20 13:05:41,561] Trial 9 finished with value: 0.8598938223938223 and parameters: {'n_estimators': 50, 'learning_rate': 0.28943473239639295, 'max_depth': 9, 'min_child_weight': 6.993785577559773, 'gamma': 0.8464827668952163, 'subsample': 0.8637621472280548, 'colsample_bytree': 0.6256479167256533}. Best is trial 6 with value: 0.8616956241956242.\n",
      "[I 2025-12-20 13:14:12,619] Trial 10 finished with value: 0.8635135135135135 and parameters: {'n_estimators': 198, 'learning_rate': 0.01092394116649165, 'max_depth': 7, 'min_child_weight': 1.1994356723758541, 'gamma': 4.568050024911163, 'subsample': 0.7191230441232227, 'colsample_bytree': 0.7591721366116809}. Best is trial 10 with value: 0.8635135135135135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost hyperparameters: {'n_estimators': 198, 'learning_rate': 0.01092394116649165, 'max_depth': 7, 'min_child_weight': 1.1994356723758541, 'gamma': 4.568050024911163, 'subsample': 0.7191230441232227, 'colsample_bytree': 0.7591721366116809}\n",
      "XGB Cross-val Accuracies: [0.89285714 0.92857143 0.89285714 0.85714286 0.85714286 0.80357143\n",
      " 0.78571429 0.8        0.87272727 0.81818182]\n",
      "XGB Mean CV Accuracy: 0.8508766233766234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [13:14:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# --- Run the optimization ---\\nstudy6 = optuna.create_study(direction=\\'maximize\\')\\nstudy6.optimize(objective_svc, n_trials=100, timeout=300)\\n\\n# --- Train final model with best parameters ---\\nbest_params6 = study6.best_params\\nbest_params6[\\'probability\\'] = True  # Ensure probability is included\\nbest_params6[\\'random_state\\'] = SEED  # Ensure reproducibility\\n\\nprint(\"Best SVM hyperparameters:\", best_params6)\\n\\nsvm_floor_final = SVC(**best_params6)\\n\\n# --- Cross-validation accuracy ---\\ncv_scores_svm = cross_val_score(svm_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\\nprint(\"SVM Cross-val Accuracies:\", cv_scores_svm)\\nprint(\"SVM Mean CV Accuracy:\", cv_scores_svm.mean())\\n\\n# --- Train on full training set (optional, if you want to save the model) ---\\nsvm_floor_final.fit(X_train, y_train)\\njoblib.dump(svm_floor_final, \\'svm_floor_pred_UJI.joblib\\')'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "# --- Run optimization ---\n",
    "study4 = optuna.create_study(direction='maximize')\n",
    "study4.optimize(objective_xgb, n_trials=100, timeout=300)\n",
    "\n",
    "# --- Best parameters ---\n",
    "best_params4 = study4.best_params\n",
    "print(\"Best XGBoost hyperparameters:\", best_params4)\n",
    "\n",
    "# --- Train final model with best params ---\n",
    "xgb_floor_final = XGBClassifier(**best_params4, use_label_encoder=False, eval_metric='mlogloss', random_state=SEED, n_jobs=-1)\n",
    "\n",
    "# --- Cross-validation accuracy ---\n",
    "cv_scores_xgb = cross_val_score(xgb_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"XGB Cross-val Accuracies:\", cv_scores_xgb)\n",
    "print(\"XGB Mean CV Accuracy:\", cv_scores_xgb.mean())\n",
    "\n",
    "# --- Train on full training set ---\n",
    "xgb_floor_final.fit(X_train, y_train)\n",
    "joblib.dump(xgb_floor_final, 'xgb_floor_pred_Tampere.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7413de6d-bc3b-443e-afbe-1b604a6f3741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:14:25,838] A new study created in memory with name: no-name-4fa333b0-9dcb-4cc3-a0da-d58fd8c9f043\n",
      "[I 2025-12-20 13:14:26,108] Trial 0 finished with value: 0.7647200772200772 and parameters: {'var_smoothing': 8.496625817489457e-07}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:26,843] Trial 1 finished with value: 0.6893661518661519 and parameters: {'var_smoothing': 1.130333588605971e-09}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:27,124] Trial 2 finished with value: 0.7234234234234234 and parameters: {'var_smoothing': 4.6051161846513976e-08}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:27,478] Trial 3 finished with value: 0.6929214929214929 and parameters: {'var_smoothing': 4.709783973178969e-09}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:27,777] Trial 4 finished with value: 0.7234234234234234 and parameters: {'var_smoothing': 4.469720019701287e-08}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:28,458] Trial 5 finished with value: 0.7073037323037323 and parameters: {'var_smoothing': 9.756791076325274e-09}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:28,691] Trial 6 finished with value: 0.7001126126126127 and parameters: {'var_smoothing': 7.837749748365457e-09}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:28,943] Trial 7 finished with value: 0.6857947232947234 and parameters: {'var_smoothing': 4.066414288978984e-10}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:29,603] Trial 8 finished with value: 0.7073037323037323 and parameters: {'var_smoothing': 1.0745164782619452e-08}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:29,871] Trial 9 finished with value: 0.6929375804375805 and parameters: {'var_smoothing': 3.0777809695449304e-09}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:30,187] Trial 10 finished with value: 0.6857947232947232 and parameters: {'var_smoothing': 7.66113934094156e-12}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:30,514] Trial 11 finished with value: 0.7647200772200772 and parameters: {'var_smoothing': 7.918961569563903e-07}. Best is trial 0 with value: 0.7647200772200772.\n",
      "[I 2025-12-20 13:14:31,159] Trial 12 finished with value: 0.771911196911197 and parameters: {'var_smoothing': 9.94416614673472e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:31,428] Trial 13 finished with value: 0.7701093951093951 and parameters: {'var_smoothing': 9.662398844737466e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:31,683] Trial 14 finished with value: 0.734202059202059 and parameters: {'var_smoothing': 1.7661044231228395e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:31,962] Trial 15 finished with value: 0.6839929214929215 and parameters: {'var_smoothing': 6.757556853365466e-11}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:32,664] Trial 16 finished with value: 0.6857947232947232 and parameters: {'var_smoothing': 1.2470223897125377e-12}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:32,959] Trial 17 finished with value: 0.734202059202059 and parameters: {'var_smoothing': 1.846005414777008e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:33,272] Trial 18 finished with value: 0.7342020592020592 and parameters: {'var_smoothing': 1.524496130205149e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:33,637] Trial 19 finished with value: 0.6839929214929215 and parameters: {'var_smoothing': 1.8960323476306356e-10}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:34,236] Trial 20 finished with value: 0.7234234234234234 and parameters: {'var_smoothing': 3.9298731695711825e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:34,513] Trial 21 finished with value: 0.7647200772200771 and parameters: {'var_smoothing': 6.959598882354129e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:34,785] Trial 22 finished with value: 0.7683075933075934 and parameters: {'var_smoothing': 9.346967354296462e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:35,512] Trial 23 finished with value: 0.7431949806949806 and parameters: {'var_smoothing': 2.801584199285754e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:35,770] Trial 24 finished with value: 0.7252252252252251 and parameters: {'var_smoothing': 7.381306003334183e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:36,123] Trial 25 finished with value: 0.7539736164736164 and parameters: {'var_smoothing': 3.9437347454043477e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:36,535] Trial 26 finished with value: 0.7144787644787645 and parameters: {'var_smoothing': 2.3853984446619265e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:37,166] Trial 27 finished with value: 0.7287966537966537 and parameters: {'var_smoothing': 1.069634970402407e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:37,427] Trial 28 finished with value: 0.7485842985842985 and parameters: {'var_smoothing': 3.4511468169168577e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:37,690] Trial 29 finished with value: 0.7647200772200772 and parameters: {'var_smoothing': 7.54136006777321e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:37,981] Trial 30 finished with value: 0.7647200772200771 and parameters: {'var_smoothing': 7.155843515691957e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:38,642] Trial 31 finished with value: 0.7701093951093951 and parameters: {'var_smoothing': 9.744660610909503e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:38,954] Trial 32 finished with value: 0.7665057915057916 and parameters: {'var_smoothing': 8.935846631087713e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:39,303] Trial 33 finished with value: 0.7485842985842985 and parameters: {'var_smoothing': 3.2909378360831614e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:39,624] Trial 34 finished with value: 0.7287966537966537 and parameters: {'var_smoothing': 1.1704454100176617e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:40,150] Trial 35 finished with value: 0.7144787644787645 and parameters: {'var_smoothing': 2.3448457861568634e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:40,419] Trial 36 finished with value: 0.7503861003861003 and parameters: {'var_smoothing': 3.759543974830993e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:40,720] Trial 37 finished with value: 0.6893661518661519 and parameters: {'var_smoothing': 1.9106121508039713e-09}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:41,402] Trial 38 finished with value: 0.7683075933075934 and parameters: {'var_smoothing': 9.341388972020615e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:41,722] Trial 39 finished with value: 0.7252252252252251 and parameters: {'var_smoothing': 6.227734192188906e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:42,100] Trial 40 finished with value: 0.7144787644787645 and parameters: {'var_smoothing': 2.4846452779886582e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:42,522] Trial 41 finished with value: 0.7701093951093951 and parameters: {'var_smoothing': 9.717770837242804e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:43,128] Trial 42 finished with value: 0.7521718146718146 and parameters: {'var_smoothing': 4.2428693598376386e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:43,416] Trial 43 finished with value: 0.7413931788931789 and parameters: {'var_smoothing': 2.2644734598680974e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:43,689] Trial 44 finished with value: 0.7575611325611324 and parameters: {'var_smoothing': 5.002561256190482e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:43,973] Trial 45 finished with value: 0.7270109395109394 and parameters: {'var_smoothing': 9.179760115092274e-08}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:44,641] Trial 46 finished with value: 0.684009009009009 and parameters: {'var_smoothing': 3.4756044260292835e-11}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:44,956] Trial 47 finished with value: 0.6875804375804375 and parameters: {'var_smoothing': 7.534346175017065e-10}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:45,304] Trial 48 finished with value: 0.7342020592020592 and parameters: {'var_smoothing': 1.704228903362021e-07}. Best is trial 12 with value: 0.771911196911197.\n",
      "[I 2025-12-20 13:14:45,597] Trial 49 finished with value: 0.771911196911197 and parameters: {'var_smoothing': 9.936846007635425e-07}. Best is trial 12 with value: 0.771911196911197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes hyperparameters: {'var_smoothing': 9.94416614673472e-07}\n",
      "GNB Cross-val Accuracies: [0.82142857 0.71428571 0.75       0.83928571 0.71428571 0.69642857\n",
      " 0.73214286 0.69090909 0.8        0.8       ]\n",
      "GNB Mean CV Accuracy: 0.7558766233766233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Decision Tree\\n# --- Run the optimization ---\\nstudy8 = optuna.create_study(direction=\\'maximize\\')\\nstudy8.optimize(objective_dt, n_trials=100, timeout=300)\\n\\n# --- Train final model with best hyperparameters ---\\nbest_params8 = study8.best_params\\nprint(\"Best hyperparameters:\", best_params8)\\n\\ndt_floor_final = DecisionTreeClassifier(**best_params8, random_state=SEED)\\n\\n# --- Cross-validation accuracy ---\\ncv_scores_dt = cross_val_score(dt_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\\nprint(\"DT Cross-val Accuracies:\", cv_scores_dt)\\nprint(\"DT Mean CV Accuracy:\", cv_scores_dt.mean())\\n\\n# --- Train on full training set (optional, if you want to save the model) ---\\ndt_floor_final.fit(X_train, y_train)\\njoblib.dump(dt_floor_final, \\'dt_floor_pred_UJI.joblib\\')'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# --- Run the optimization ---\n",
    "study7 = optuna.create_study(direction='maximize')\n",
    "study7.optimize(objective_gnb, n_trials=50, timeout=200)\n",
    "\n",
    "# --- Train final model with best hyperparameters ---\n",
    "best_params7 = study7.best_params\n",
    "print(\"Best Naive Bayes hyperparameters:\", best_params7)\n",
    "\n",
    "gnb_floor_final = GaussianNB(**best_params7)\n",
    "\n",
    "# --- Cross-validation accuracy ---\n",
    "cv_scores_gnb = cross_val_score(gnb_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"GNB Cross-val Accuracies:\", cv_scores_gnb)\n",
    "print(\"GNB Mean CV Accuracy:\", cv_scores_gnb.mean())\n",
    "\n",
    "# --- Train on full training set ---\n",
    "gnb_floor_final.fit(X_train, y_train)\n",
    "joblib.dump(gnb_floor_final, 'gnb_floor_pred_Tampere.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2736513-513c-4b55-8b3c-f036c013e127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:14:47,619] A new study created in memory with name: no-name-fbe08a00-9c8e-4703-ac9a-3cd9d2d45105\n",
      "[I 2025-12-20 13:14:52,781] Trial 0 finished with value: 0.40400579150579147 and parameters: {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 11, 'min_samples_leaf': 3, 'n_estimators': 95, 'learning_rate': 0.03054607375138277}. Best is trial 0 with value: 0.40400579150579147.\n",
      "[I 2025-12-20 13:15:26,942] Trial 1 finished with value: 0.8796492921492922 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 17, 'n_estimators': 224, 'learning_rate': 0.9651859598226136}. Best is trial 1 with value: 0.8796492921492922.\n",
      "[I 2025-12-20 13:15:34,656] Trial 2 finished with value: 0.6050032175032175 and parameters: {'criterion': 'log_loss', 'max_depth': 1, 'min_samples_split': 12, 'min_samples_leaf': 19, 'n_estimators': 191, 'learning_rate': 0.11054511641075453}. Best is trial 1 with value: 0.8796492921492922.\n",
      "[I 2025-12-20 13:15:52,077] Trial 3 finished with value: 0.8599581724581725 and parameters: {'criterion': 'log_loss', 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 10, 'n_estimators': 169, 'learning_rate': 0.07414263746181299}. Best is trial 1 with value: 0.8796492921492922.\n",
      "[I 2025-12-20 13:15:55,253] Trial 4 finished with value: 0.6337998712998713 and parameters: {'criterion': 'log_loss', 'max_depth': 1, 'min_samples_split': 18, 'min_samples_leaf': 1, 'n_estimators': 66, 'learning_rate': 0.5390947989494763}. Best is trial 1 with value: 0.8796492921492922.\n",
      "[I 2025-12-20 13:17:24,652] Trial 5 finished with value: 0.881515444015444 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'n_estimators': 220, 'learning_rate': 0.05277780330365538}. Best is trial 5 with value: 0.881515444015444.\n",
      "[I 2025-12-20 13:19:21,557] Trial 6 finished with value: 0.8563867438867439 and parameters: {'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 17, 'n_estimators': 211, 'learning_rate': 0.2271042066991219}. Best is trial 5 with value: 0.881515444015444.\n",
      "[I 2025-12-20 13:19:44,844] Trial 7 finished with value: 0.8634974259974261 and parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 17, 'n_estimators': 211, 'learning_rate': 0.14568009856763794}. Best is trial 5 with value: 0.881515444015444.\n",
      "[I 2025-12-20 13:20:01,661] Trial 8 finished with value: 0.8689028314028315 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 14, 'n_estimators': 121, 'learning_rate': 0.45385785867837836}. Best is trial 5 with value: 0.881515444015444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'n_estimators': 220, 'learning_rate': 0.05277780330365538}\n",
      "AdaBoost Cross-val Accuracies: [0.92857143 0.94642857 0.89285714 0.92857143 0.85714286 0.85714286\n",
      " 0.82142857 0.89090909 0.90909091 0.87272727]\n",
      "AdaBoost Mean CV Accuracy: 0.8904870129870129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adaboost_floor_pred_UJI.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "\n",
    "# --- Run the optimization ---\n",
    "study_ab = optuna.create_study(direction='maximize')\n",
    "study_ab.optimize(objective_adaboost, n_trials=100, timeout=300)\n",
    "\n",
    "# --- Train final model with best hyperparameters ---\n",
    "best_params_ab = study_ab.best_params\n",
    "print(\"Best hyperparameters:\", best_params_ab)\n",
    "\n",
    "# Extract AdaBoost-specific parameters\n",
    "ada_params = {\n",
    "    'n_estimators': best_params_ab.pop('n_estimators'),\n",
    "    'learning_rate': best_params_ab.pop('learning_rate'),\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "# Remaining params go to base estimator (DecisionTree)\n",
    "base_estimator = DecisionTreeClassifier(**best_params_ab, random_state=SEED)\n",
    "\n",
    "# Build final AdaBoost model\n",
    "ab_floor_final = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    **ada_params\n",
    ")\n",
    "\n",
    "# --- Cross-validation accuracy ---\n",
    "cv_scores_ab = cross_val_score(ab_floor_final, X_train, y_train, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"AdaBoost Cross-val Accuracies:\", cv_scores_ab)\n",
    "print(\"AdaBoost Mean CV Accuracy:\", cv_scores_ab.mean())\n",
    "\n",
    "# --- Train on full training set ---\n",
    "ab_floor_final.fit(X_train, y_train)\n",
    "joblib.dump(ab_floor_final, 'adaboost_floor_pred_Tampere.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b8a4cf-26c6-4e72-8bfa-efc7cf1b7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        (\"KNN\", knn_floor_final),\n",
    "        (\"RF\", rf_floor_final),\n",
    "        (\"LGB\", lgb_floor_final),\n",
    "        (\"XGB\", xgb_floor_final),\n",
    "        (\"NB\", gnb_floor_final),\n",
    "        (\"AB\", ab_floor_final)\n",
    "    ]\n",
    "\n",
    "accuracy_knn = cv_scores_knn.mean()\n",
    "accuracy_rf = cv_scores_rf.mean()\n",
    "accuracy_lgb = cv_scores_lgb.mean()\n",
    "accuracy_xgb = cv_scores_xgb.mean()\n",
    "accuracy_gnb = cv_scores_gnb.mean()\n",
    "accuracy_ab = cv_scores_ab.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967f552c-f0b5-45be-b750-14208680b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IEO-CVV\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def ieo_cvv_ensemble_selection(models, X_train, y_train, X_test, y_test, cv=10, patience=3):\n",
    "    print(\"Initializing Iterative Ensemble Optimization with CV Voting (IEO-CVV)...\")\n",
    "\n",
    "    # --- Step 1: Compute cross-val scores and predictions ---\n",
    "    model_scores = {}\n",
    "    model_preds = {}\n",
    "\n",
    "    for name, model in models:\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "        acc = cv_scores.mean()\n",
    "        model_scores[name] = acc\n",
    "\n",
    "        y_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv, method='predict', n_jobs=-1)\n",
    "        model_preds[name] = y_pred_cv\n",
    "\n",
    "        print(f\"{name} CV Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Sort models by CV accuracy\n",
    "    sorted_models = sorted(models, key=lambda m: model_scores[m[0]], reverse=True)\n",
    "\n",
    "    # --- Ensemble voting function (CV-based predictions) ---\n",
    "    def ensemble_predict_cv(selected_model_names):\n",
    "        preds = np.array([model_preds[name] for name in selected_model_names])\n",
    "        weights = np.array([model_scores[name] for name in selected_model_names])\n",
    "        weighted_preds = []\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "            classes = np.unique(preds[:, i])\n",
    "            vote_score = {c: 0.0 for c in classes}\n",
    "            for j, c in enumerate(preds[:, i]):\n",
    "                vote_score[c] += weights[j]\n",
    "            final_class = max(vote_score, key=vote_score.get)\n",
    "            weighted_preds.append(final_class)\n",
    "\n",
    "        return np.array(weighted_preds)\n",
    "\n",
    "    # --- Step 2: Initialize ensemble with top 2 models ---\n",
    "    ensemble = sorted_models[:2]\n",
    "    ensemble_names = [name for name, _ in ensemble]\n",
    "    best_acc = accuracy_score(y_train, ensemble_predict_cv(ensemble_names))\n",
    "    print(f\"Initial Ensemble: {[n for n, _ in ensemble]} - Train Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    # --- Step 3: Iterative forward selection with backward pruning ---\n",
    "    patience_counter = 0\n",
    "    remaining_models = sorted_models[2:]\n",
    "\n",
    "    while remaining_models and patience_counter < patience:\n",
    "        improved = False\n",
    "\n",
    "        name, model = remaining_models.pop(0)\n",
    "        temp_ensemble = ensemble + [(name, model)]\n",
    "        temp_names = [n for n, _ in temp_ensemble]\n",
    "\n",
    "        y_pred_temp = ensemble_predict_cv(temp_names)\n",
    "        new_acc = accuracy_score(y_train, y_pred_temp)\n",
    "\n",
    "        if new_acc > best_acc:\n",
    "            ensemble = temp_ensemble\n",
    "            best_acc = new_acc\n",
    "            improved = True\n",
    "            patience_counter = 0\n",
    "            print(f\"Added {name} - Improved Train Accuracy: {new_acc:.4f}\")\n",
    "\n",
    "            # --- Backward pruning ---\n",
    "            pruned = True\n",
    "            while pruned and len(ensemble) > 1:\n",
    "                pruned = False\n",
    "                for n, m in ensemble:\n",
    "                    if n == name:\n",
    "                        continue\n",
    "                    temp_ensemble_pruned = [(x, y) for x, y in ensemble if x != n]\n",
    "                    temp_names_pruned = [x for x, _ in temp_ensemble_pruned]\n",
    "                    y_pred_pruned = ensemble_predict_cv(temp_names_pruned)\n",
    "                    pruned_acc = accuracy_score(y_train, y_pred_pruned)\n",
    "\n",
    "                    if pruned_acc >= best_acc:\n",
    "                        print(f\"Pruned {n} - Accuracy maintained/improved: {pruned_acc:.4f}\")\n",
    "                        ensemble = temp_ensemble_pruned\n",
    "                        best_acc = pruned_acc\n",
    "                        pruned = True\n",
    "                        break  # Restart pruning loop\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Ignored {name} - No improvement: {new_acc:.4f} (Patience: {patience_counter}/{patience})\")\n",
    "\n",
    "    # --- Final weights based on normalized CV accuracies ---\n",
    "    final_names = [n for n, _ in ensemble]\n",
    "    weights = {name: model_scores[name] for name in final_names}\n",
    "    total = sum(weights.values())\n",
    "    weights = {k: v / total for k, v in weights.items()}\n",
    "\n",
    "    print(\"Final Ensemble Members:\", final_names)\n",
    "    print(\"Final Ensemble Train Accuracy:\", best_acc)\n",
    "\n",
    "    # --- Step 4: Retrain final models and test ensemble ---\n",
    "    print(\"\\nRetraining final models and evaluating on test set...\")\n",
    "    for name, model in ensemble:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    def ensemble_predict_test(selected_models, X):\n",
    "        preds = np.array([m.predict(X).ravel() for _, m in selected_models])\n",
    "        weights = np.array([model_scores[name] for name, _ in selected_models])\n",
    "        weighted_preds = []\n",
    "        for i in range(X.shape[0]):\n",
    "            classes = np.unique(preds[:, i])\n",
    "            vote_score = {c: 0.0 for c in classes}\n",
    "            for j, c in enumerate(preds[:, i]):\n",
    "                vote_score[c] += weights[j]\n",
    "            final_class = max(vote_score, key=vote_score.get)\n",
    "            weighted_preds.append(final_class)\n",
    "        return np.array(weighted_preds)\n",
    "\n",
    "    y_pred_test = ensemble_predict_test(ensemble, X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Final Ensemble Test Accuracy:\", test_acc)\n",
    "\n",
    "    return ensemble, best_acc, weights, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1bb8938-791e-4c46-92f0-d3260743a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(ensemble, X, model_scores):\n",
    "    preds = np.array([m.predict(X).ravel() for _, m in ensemble])  # predictions of all models\n",
    "    weights = np.array([model_scores[name] for name, _ in ensemble])  # accuracy-based weights\n",
    "\n",
    "    weighted_preds = []\n",
    "    for i in range(X.shape[0]):\n",
    "        classes, counts = np.unique(preds[:, i], return_counts=True)\n",
    "        # Weighted voting\n",
    "        vote_score = {c: 0 for c in classes}\n",
    "        for j, c in enumerate(preds[:, i]):\n",
    "            vote_score[c] += weights[j]\n",
    "        weighted_preds.append(max(vote_score, key=vote_score.get))\n",
    "\n",
    "    return np.array(weighted_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dffb4d-9ad2-43fd-8848-7e403188821f",
   "metadata": {},
   "source": [
    "# IEO-CVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb7abee7-d647-479e-917b-bf768f16ad36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Iterative Ensemble Optimization with CV Voting (IEO-CVV)...\n",
      "Evaluating KNN...\n",
      "KNN CV Accuracy: 0.9010\n",
      "Evaluating RF...\n",
      "RF CV Accuracy: 0.9083\n",
      "Evaluating LGB...\n",
      "LGB CV Accuracy: 0.7845\n",
      "Evaluating XGB...\n",
      "XGB CV Accuracy: 0.8509\n",
      "Evaluating NB...\n",
      "NB CV Accuracy: 0.7559\n",
      "Evaluating AB...\n",
      "AB CV Accuracy: 0.8905\n",
      "Initial Ensemble: ['RF', 'KNN'] - Train Accuracy: 0.9084\n",
      "Added AB - Improved Train Accuracy: 0.9246\n",
      "Added XGB - Improved Train Accuracy: 0.9264\n",
      "Ignored LGB - No improvement: 0.9120 (Patience: 1/3)\n",
      "Ignored NB - No improvement: 0.9174 (Patience: 2/3)\n",
      "Final Ensemble Members: ['RF', 'KNN', 'AB', 'XGB']\n",
      "Final Ensemble Train Accuracy: 0.926391382405745\n",
      "\n",
      "Retraining final models and evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMITL\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\core.py:158: UserWarning: [13:21:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ensemble Test Accuracy: 0.9214285714285714\n",
      "Training time: 2146.30 seconds\n"
     ]
    }
   ],
   "source": [
    "ensemble2, best_acc2, ensemble_weights2, test_acc2 = ieo_cvv_ensemble_selection(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "end_time1 = time.time()\n",
    "\n",
    "training_time1 = end_time1 - start_time1\n",
    "print(f\"Training time: {training_time1:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "783054be-9a5f-4806-8768-afbfbd55a208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.90 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time3 = time.time()\n",
    "\n",
    "y_floor_predictions2 = ensemble_predict(ensemble2, X_target, ensemble_weights2)\n",
    "\n",
    "end_time3 = time.time()\n",
    "training_time3 = end_time3 - start_time3\n",
    "print(f\"Training time: {training_time3:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce4b94d8-3b4b-42f2-a76f-773049460ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor using Ensemble Accuracy: 0.9240698557327259\n"
     ]
    }
   ],
   "source": [
    "accuracy_floor_ensemble2 = accuracy_score(y_target_floor, y_floor_predictions2)\n",
    "print(\"Floor using Ensemble Accuracy:\", accuracy_floor_ensemble2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97067b-15f2-46a1-9663-f262c55ed74e",
   "metadata": {},
   "source": [
    "# Location Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b418fe6-e137-40a0-8283-29f0853568e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances,make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d7c0ef4-72f7-4a2f-83c1-14c96f03d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data split ---\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_coordinate, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def mean_euclidean_distance(y_true, y_pred):\n",
    "    return np.mean(np.linalg.norm(y_pred - y_true, axis=1))\n",
    "\n",
    "euclidean_scorer = make_scorer(mean_euclidean_distance, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "103bb8fc-350c-4987-8384-419ad0ac8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time2 = time.time()\n",
    "\n",
    "# --- Random Forest Regressor ---\n",
    "def objective_rfr(trial):\n",
    "    rf = RandomForestRegressor(\n",
    "        max_depth=trial.suggest_categorical('max_depth', [None] + list(range(5, 51))),\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 500),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        max_features=trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_train2):\n",
    "        X_train_fold = X_train2.iloc[train_idx]\n",
    "        X_valid_fold = X_train2.iloc[valid_idx]\n",
    "        y_train_fold = y_train2.iloc[train_idx]\n",
    "        y_valid_fold = y_train2.iloc[valid_idx]\n",
    "\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        preds = rf.predict(X_valid_fold)\n",
    "\n",
    "        fold_score = np.mean(np.linalg.norm(preds - y_valid_fold.to_numpy(), axis=1))\n",
    "        scores.append(fold_score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# --- XGBoost Regressor ---\n",
    "def objective_xgbr(trial):\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "        min_child_weight=trial.suggest_float('min_child_weight', 1, 10),\n",
    "        gamma=trial.suggest_float('gamma', 0, 5),\n",
    "        subsample=trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(\n",
    "        model,\n",
    "        X_train2,\n",
    "        y_train2,\n",
    "        cv=10,\n",
    "        scoring=euclidean_scorer,\n",
    "        n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# --- AdaBoost Regressor ---\n",
    "def objective_adaboost_r(trial):\n",
    "    base_estimator = DecisionTreeRegressor(\n",
    "        max_depth=trial.suggest_int('max_depth', 2, 10),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    ada = AdaBoostRegressor(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    model = MultiOutputRegressor(ada)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train2,\n",
    "        y_train2,\n",
    "        cv=cv,\n",
    "        scoring=euclidean_scorer,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return -scores.mean()\n",
    "\n",
    "\n",
    "# --- KNN Regressor ---\n",
    "def objective_knnr(trial):\n",
    "    knn = KNeighborsRegressor(\n",
    "        n_neighbors=trial.suggest_int('n_neighbors', 1, 50),\n",
    "        p=trial.suggest_int('p', 1, 5),\n",
    "        metric=trial.suggest_categorical('metric', ['minkowski', 'euclidean', 'manhattan']),\n",
    "        weights=knn_weight\n",
    "    )\n",
    "\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_train2):\n",
    "        X_train_fold = X_train2.iloc[train_idx]\n",
    "        X_valid_fold = X_train2.iloc[valid_idx]\n",
    "        y_train_fold = y_train2.iloc[train_idx]\n",
    "        y_valid_fold = y_train2.iloc[valid_idx]\n",
    "\n",
    "        knn.fit(X_train_fold, y_train_fold)\n",
    "        preds = knn.predict(X_valid_fold)\n",
    "\n",
    "        fold_score = np.mean(np.linalg.norm(preds - y_valid_fold.to_numpy(), axis=1))\n",
    "        scores.append(fold_score)\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7043be5-8c91-4931-9c67-fdce0530f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(y_true, y_pred):\n",
    "    return np.mean(np.linalg.norm(y_true - y_pred, axis=1))\n",
    "\n",
    "\n",
    "def objective_lgbr(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    base_model = lgb.LGBMRegressor(**param)\n",
    "    model = MultiOutputRegressor(base_model)\n",
    "\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X_train2):\n",
    "        X_train_fold = X_train2.iloc[train_idx]\n",
    "        X_valid_fold = X_train2.iloc[valid_idx]\n",
    "        y_train_fold = y_train2.iloc[train_idx]\n",
    "        y_valid_fold = y_train2.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        preds = model.predict(X_valid_fold)\n",
    "\n",
    "        score = euclidean_distance(y_valid_fold.to_numpy(), preds)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71b4e08f-5e5f-4a87-a37c-4de09d43c771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:25:25,533] A new study created in memory with name: no-name-42651de0-c78d-4e6e-bd34-621c67d16b18\n",
      "[I 2025-12-20 13:26:21,735] Trial 0 finished with value: 14.513615103338633 and parameters: {'n_neighbors': 38, 'p': 2, 'metric': 'euclidean'}. Best is trial 0 with value: 14.513615103338633.\n",
      "[I 2025-12-20 13:26:22,634] Trial 1 finished with value: 11.855150872098358 and parameters: {'n_neighbors': 15, 'p': 2, 'metric': 'euclidean'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:24,363] Trial 2 finished with value: 14.51734964588031 and parameters: {'n_neighbors': 37, 'p': 2, 'metric': 'manhattan'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:25,213] Trial 3 finished with value: 12.744931565655524 and parameters: {'n_neighbors': 23, 'p': 5, 'metric': 'euclidean'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:26,787] Trial 4 finished with value: 15.514906005943402 and parameters: {'n_neighbors': 46, 'p': 5, 'metric': 'manhattan'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:28,155] Trial 5 finished with value: 15.520786387455331 and parameters: {'n_neighbors': 47, 'p': 4, 'metric': 'euclidean'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:30,744] Trial 6 finished with value: 14.717386256600701 and parameters: {'n_neighbors': 29, 'p': 4, 'metric': 'minkowski'}. Best is trial 1 with value: 11.855150872098358.\n",
      "[I 2025-12-20 13:26:31,824] Trial 7 finished with value: 11.248318729043223 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'manhattan'}. Best is trial 7 with value: 11.248318729043223.\n",
      "[I 2025-12-20 13:26:33,473] Trial 8 finished with value: 12.266640163047105 and parameters: {'n_neighbors': 21, 'p': 3, 'metric': 'manhattan'}. Best is trial 7 with value: 11.248318729043223.\n",
      "[I 2025-12-20 13:26:34,728] Trial 9 finished with value: 15.711277959625296 and parameters: {'n_neighbors': 48, 'p': 1, 'metric': 'minkowski'}. Best is trial 7 with value: 11.248318729043223.\n",
      "[I 2025-12-20 13:26:36,153] Trial 10 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 10.815644996127292.\n",
      "[I 2025-12-20 13:26:37,494] Trial 11 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'manhattan'}. Best is trial 11 with value: 10.071429416244877.\n",
      "[I 2025-12-20 13:26:39,091] Trial 12 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 11 with value: 10.071429416244877.\n",
      "[I 2025-12-20 13:26:40,032] Trial 13 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:41,738] Trial 14 finished with value: 10.405014724198532 and parameters: {'n_neighbors': 9, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:42,688] Trial 15 finished with value: 10.405014724198532 and parameters: {'n_neighbors': 9, 'p': 3, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:44,446] Trial 16 finished with value: 10.142580161549802 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:45,596] Trial 17 finished with value: 10.02779856884364 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:47,217] Trial 18 finished with value: 11.723325353265832 and parameters: {'n_neighbors': 17, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:49,353] Trial 19 finished with value: 14.46483765697713 and parameters: {'n_neighbors': 31, 'p': 3, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:50,917] Trial 20 finished with value: 10.142580161549802 and parameters: {'n_neighbors': 7, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:52,105] Trial 21 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:53,550] Trial 22 finished with value: 10.03595311057876 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:54,679] Trial 23 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:56,378] Trial 24 finished with value: 10.972184688655148 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:57,433] Trial 25 finished with value: 12.009614095288184 and parameters: {'n_neighbors': 19, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:26:59,119] Trial 26 finished with value: 11.09006856253684 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:00,076] Trial 27 finished with value: 10.405014724198532 and parameters: {'n_neighbors': 9, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:02,801] Trial 28 finished with value: 11.055024527558768 and parameters: {'n_neighbors': 4, 'p': 3, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:04,025] Trial 29 finished with value: 11.224017627778277 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:05,575] Trial 30 finished with value: 13.129834113948316 and parameters: {'n_neighbors': 26, 'p': 4, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:06,585] Trial 31 finished with value: 10.02779856884364 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:08,526] Trial 32 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:09,499] Trial 33 finished with value: 11.566503950726597 and parameters: {'n_neighbors': 16, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:11,335] Trial 34 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:12,201] Trial 35 finished with value: 14.739126725715101 and parameters: {'n_neighbors': 40, 'p': 1, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:13,724] Trial 36 finished with value: 10.579047880855306 and parameters: {'n_neighbors': 10, 'p': 3, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:14,812] Trial 37 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:16,175] Trial 38 finished with value: 10.675645912287742 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:17,308] Trial 39 finished with value: 14.51734964588031 and parameters: {'n_neighbors': 37, 'p': 5, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:18,635] Trial 40 finished with value: 15.182630316906838 and parameters: {'n_neighbors': 43, 'p': 3, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:19,621] Trial 41 finished with value: 10.02779856884364 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:21,284] Trial 42 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:22,190] Trial 43 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:23,797] Trial 44 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:25,665] Trial 45 finished with value: 12.576945568215494 and parameters: {'n_neighbors': 15, 'p': 3, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:27,146] Trial 46 finished with value: 10.253933720424012 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:28,165] Trial 47 finished with value: 10.972184688655148 and parameters: {'n_neighbors': 12, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:29,802] Trial 48 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:30,669] Trial 49 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:31,963] Trial 50 finished with value: 10.22521802731119 and parameters: {'n_neighbors': 3, 'p': 3, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:32,898] Trial 51 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 4, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:34,293] Trial 52 finished with value: 15.872643173919187 and parameters: {'n_neighbors': 50, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:35,298] Trial 53 finished with value: 13.912078576328962 and parameters: {'n_neighbors': 32, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:36,630] Trial 54 finished with value: 10.142580161549802 and parameters: {'n_neighbors': 7, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:37,556] Trial 55 finished with value: 10.03595311057876 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:39,027] Trial 56 finished with value: 10.579047880855306 and parameters: {'n_neighbors': 10, 'p': 2, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:39,918] Trial 57 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:41,417] Trial 58 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:42,260] Trial 59 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:43,723] Trial 60 finished with value: 12.543581289791842 and parameters: {'n_neighbors': 23, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:44,575] Trial 61 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:45,925] Trial 62 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:46,893] Trial 63 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:48,278] Trial 64 finished with value: 10.142580161549802 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:49,338] Trial 65 finished with value: 10.405014724198532 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:50,629] Trial 66 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:51,591] Trial 67 finished with value: 10.03595311057876 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:52,962] Trial 68 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:53,879] Trial 69 finished with value: 10.253933720424012 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:55,358] Trial 70 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:56,233] Trial 71 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:57,815] Trial 72 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:27:58,671] Trial 73 finished with value: 10.02779856884364 and parameters: {'n_neighbors': 4, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:00,180] Trial 74 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:01,025] Trial 75 finished with value: 10.862809564528813 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:02,401] Trial 76 finished with value: 10.03595311057876 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:03,432] Trial 77 finished with value: 10.756755305626996 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:04,728] Trial 78 finished with value: 10.019072050197297 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:05,756] Trial 79 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'minkowski'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:07,071] Trial 80 finished with value: 10.579047880855306 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:08,005] Trial 81 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:09,450] Trial 82 finished with value: 10.02779856884364 and parameters: {'n_neighbors': 4, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:10,411] Trial 83 finished with value: 10.815644996127292 and parameters: {'n_neighbors': 1, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:11,868] Trial 84 finished with value: 10.03595311057876 and parameters: {'n_neighbors': 6, 'p': 4, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:12,745] Trial 85 finished with value: 9.938468871996047 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:28:15,108] Trial 86 finished with value: 10.071429416244877 and parameters: {'n_neighbors': 2, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:29:54,074] Trial 87 finished with value: 10.527437536874448 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'euclidean'}. Best is trial 13 with value: 9.938468871996047.\n",
      "[I 2025-12-20 13:31:28,975] Trial 88 finished with value: 10.253933720424012 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'manhattan'}. Best is trial 13 with value: 9.938468871996047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNNR hyperparameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}\n",
      "Cross-val error (per fold): [ 9.84055607  9.61061668  9.91775814 10.86160379  8.97127118 11.32157215\n",
      "  9.6028162   8.9099713  11.3454802   9.00304301]\n",
      "Mean Cross-val error: 9.938468871996047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['knn_coordinate_pred_UJI_reg.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=0)\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "# --- KNNR ---\n",
    "study1 = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study1.optimize(objective_knnr, n_trials=100, timeout=300)\n",
    "\n",
    "best_params1r = study1.best_params\n",
    "print(\"Best KNNR hyperparameters:\", best_params1r)\n",
    "\n",
    "knn_coordinate_final = KNeighborsRegressor(\n",
    "    n_neighbors=best_params1r['n_neighbors'],\n",
    "    weights=knn_weight,\n",
    "    p=best_params1r['p'],\n",
    "    metric=best_params1r['metric']\n",
    ")\n",
    "\n",
    "cv_scores_knn = cross_val_score(knn_coordinate_final, X_train2, y_train2,\n",
    "                                cv=cv, scoring=euclidean_scorer, n_jobs=-1)\n",
    "\n",
    "print(\"Cross-val error (per fold):\", -cv_scores_knn)\n",
    "print(\"Mean Cross-val error:\", -cv_scores_knn.mean())\n",
    "\n",
    "knn_coordinate_final.fit(X_train2, y_train2)\n",
    "joblib.dump(knn_coordinate_final, 'knn_coordinate_pred_UJI_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97e0ff5e-cbc1-4f58-997f-650b252efb4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:31:55,405] A new study created in memory with name: no-name-4285636c-2513-46c6-8fdb-bc7ce0c16981\n",
      "[I 2025-12-20 13:34:11,190] Trial 0 finished with value: 13.044391436897268 and parameters: {'max_depth': 47, 'n_estimators': 397, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 0 with value: 13.044391436897268.\n",
      "[I 2025-12-20 13:34:19,226] Trial 1 finished with value: 15.474693759188018 and parameters: {'max_depth': 21, 'n_estimators': 217, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 13.044391436897268.\n",
      "[I 2025-12-20 13:34:22,133] Trial 2 finished with value: 12.510926504503244 and parameters: {'max_depth': 33, 'n_estimators': 58, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 12.510926504503244.\n",
      "[I 2025-12-20 13:34:26,398] Trial 3 finished with value: 11.684998339393083 and parameters: {'max_depth': 26, 'n_estimators': 120, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 3 with value: 11.684998339393083.\n",
      "[I 2025-12-20 13:34:38,211] Trial 4 finished with value: 10.616704643402567 and parameters: {'max_depth': 41, 'n_estimators': 353, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 4 with value: 10.616704643402567.\n",
      "[I 2025-12-20 13:34:43,557] Trial 5 finished with value: 19.666272165628826 and parameters: {'max_depth': 47, 'n_estimators': 193, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 4 with value: 10.616704643402567.\n",
      "[I 2025-12-20 13:34:48,494] Trial 6 finished with value: 13.678895999661245 and parameters: {'max_depth': 24, 'n_estimators': 186, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 4 with value: 10.616704643402567.\n",
      "[I 2025-12-20 13:35:01,528] Trial 7 finished with value: 10.700083399851824 and parameters: {'max_depth': 18, 'n_estimators': 426, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 4 with value: 10.616704643402567.\n",
      "[I 2025-12-20 13:35:08,023] Trial 8 finished with value: 9.90004408648019 and parameters: {'max_depth': 35, 'n_estimators': 226, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:16,944] Trial 9 finished with value: 20.152861963707434 and parameters: {'max_depth': 7, 'n_estimators': 437, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:24,090] Trial 10 finished with value: 11.595912583202418 and parameters: {'max_depth': 15, 'n_estimators': 315, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:33,637] Trial 11 finished with value: 10.377067574491655 and parameters: {'max_depth': 35, 'n_estimators': 335, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:40,783] Trial 12 finished with value: 10.530309001812004 and parameters: {'max_depth': 35, 'n_estimators': 273, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:47,154] Trial 13 finished with value: 13.08666047973488 and parameters: {'max_depth': 35, 'n_estimators': 270, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:54,337] Trial 14 finished with value: 14.494897091696128 and parameters: {'max_depth': 37, 'n_estimators': 351, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:35:59,144] Trial 15 finished with value: 12.57952170583668 and parameters: {'max_depth': 12, 'n_estimators': 235, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:36:10,962] Trial 16 finished with value: 10.664586492648905 and parameters: {'max_depth': 49, 'n_estimators': 483, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:36:15,018] Trial 17 finished with value: 17.6026679221552 and parameters: {'max_depth': 6, 'n_estimators': 145, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:36:26,387] Trial 18 finished with value: 13.112373295429327 and parameters: {'max_depth': 22, 'n_estimators': 349, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 8 with value: 9.90004408648019.\n",
      "[I 2025-12-20 13:37:43,866] Trial 19 finished with value: 22.207162724366565 and parameters: {'max_depth': 5, 'n_estimators': 306, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 8 with value: 9.90004408648019.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RFR hyperparameters: {'max_depth': 35, 'n_estimators': 226, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "Cross-val error (per fold): [ 9.37031202  9.55054381  9.24750892  9.78214836 10.42788266 11.41578402\n",
      " 11.29755655  9.32198312  8.65054714  9.93617426]\n",
      "Mean Cross-val error: 9.900044086480191\n"
     ]
    }
   ],
   "source": [
    "# --- RFR ---\n",
    "study2 = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study2.optimize(objective_rfr, n_trials=100, timeout=300)\n",
    "\n",
    "best_params2r = study2.best_params\n",
    "print(\"Best RFR hyperparameters:\", best_params2r)\n",
    "\n",
    "rf_coordinate_final = RandomForestRegressor(**best_params2r, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf_coordinate_final, X_train2, y_train2,\n",
    "                               cv=cv, scoring=euclidean_scorer, n_jobs=-1)\n",
    "\n",
    "print(\"Cross-val error (per fold):\", -cv_scores_rf)\n",
    "print(\"Mean Cross-val error:\", -cv_scores_rf.mean())\n",
    "\n",
    "rf_coordinate_final.fit(X_train2, y_train2)\n",
    "joblib.dump(rf_coordinate_final, 'rf_coordinate_pred_Tampere_reg.pkl')\n",
    "rf_loaded2 = joblib.load('rf_coordinate_pred_Tampere_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef45e2e-80e4-46d0-a4cb-5a60d301dfb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:39:02,561] A new study created in memory with name: no-name-4d62153c-1e88-44d1-9aa0-2a8ecb5879b9\n",
      "[I 2025-12-20 13:40:00,271] Trial 0 finished with value: -11.56744714933195 and parameters: {'n_estimators': 121, 'learning_rate': 0.2036276080150736, 'max_depth': 7, 'min_child_weight': 7.699235973689632, 'gamma': 2.3307598959364837, 'subsample': 0.8161572210321502, 'colsample_bytree': 0.8117116731526695}. Best is trial 0 with value: -11.56744714933195.\n",
      "[I 2025-12-20 13:40:50,744] Trial 1 finished with value: -10.966461935369928 and parameters: {'n_estimators': 92, 'learning_rate': 0.10547285998770388, 'max_depth': 6, 'min_child_weight': 4.858129836564612, 'gamma': 3.6224020373205734, 'subsample': 0.9122728542996699, 'colsample_bytree': 0.8399675305595176}. Best is trial 1 with value: -10.966461935369928.\n",
      "[I 2025-12-20 13:41:24,286] Trial 2 finished with value: -11.052902065398715 and parameters: {'n_estimators': 106, 'learning_rate': 0.0564550006116341, 'max_depth': 8, 'min_child_weight': 7.730211748864597, 'gamma': 3.679640244613797, 'subsample': 0.9498751519446, 'colsample_bytree': 0.7162873617058566}. Best is trial 1 with value: -10.966461935369928.\n",
      "[I 2025-12-20 13:41:58,682] Trial 3 finished with value: -12.068567284483358 and parameters: {'n_estimators': 195, 'learning_rate': 0.023762629118282544, 'max_depth': 5, 'min_child_weight': 9.983622327639655, 'gamma': 1.6072977844521978, 'subsample': 0.762405568385321, 'colsample_bytree': 0.5955928905493004}. Best is trial 1 with value: -10.966461935369928.\n",
      "[I 2025-12-20 13:42:31,281] Trial 4 finished with value: -10.84554814554113 and parameters: {'n_estimators': 124, 'learning_rate': 0.17055677852167897, 'max_depth': 10, 'min_child_weight': 2.771480677077228, 'gamma': 2.3203792416284816, 'subsample': 0.6345186712870745, 'colsample_bytree': 0.8109548717455979}. Best is trial 4 with value: -10.84554814554113.\n",
      "[I 2025-12-20 13:43:16,906] Trial 5 finished with value: -10.628582167321415 and parameters: {'n_estimators': 165, 'learning_rate': 0.06586542599198657, 'max_depth': 6, 'min_child_weight': 2.6964633308528714, 'gamma': 4.772078817908022, 'subsample': 0.770876868584266, 'colsample_bytree': 0.8209973499840408}. Best is trial 5 with value: -10.628582167321415.\n",
      "[I 2025-12-20 13:43:28,922] Trial 6 finished with value: -10.877993424791145 and parameters: {'n_estimators': 165, 'learning_rate': 0.33152128904465833, 'max_depth': 7, 'min_child_weight': 1.2175107813429453, 'gamma': 3.1305301134421, 'subsample': 0.9100725978802416, 'colsample_bytree': 0.8221243099571987}. Best is trial 5 with value: -10.628582167321415.\n",
      "[I 2025-12-20 13:43:33,820] Trial 7 finished with value: -11.311067306540291 and parameters: {'n_estimators': 151, 'learning_rate': 0.04035222731457223, 'max_depth': 5, 'min_child_weight': 3.207578140201469, 'gamma': 0.14196447161203662, 'subsample': 0.7717693965207882, 'colsample_bytree': 0.741124167059406}. Best is trial 5 with value: -10.628582167321415.\n",
      "[I 2025-12-20 13:43:36,859] Trial 8 finished with value: -14.426084697940604 and parameters: {'n_estimators': 104, 'learning_rate': 0.02158258420306323, 'max_depth': 7, 'min_child_weight': 7.088351262377502, 'gamma': 3.9436170312544077, 'subsample': 0.5093670922324238, 'colsample_bytree': 0.8050155608319296}. Best is trial 5 with value: -10.628582167321415.\n",
      "[I 2025-12-20 13:43:38,536] Trial 9 finished with value: -23.118785602157693 and parameters: {'n_estimators': 66, 'learning_rate': 0.020875748743000057, 'max_depth': 3, 'min_child_weight': 7.984894776846095, 'gamma': 3.7181292419345007, 'subsample': 0.5955700347681805, 'colsample_bytree': 0.5826506692308488}. Best is trial 5 with value: -10.628582167321415.\n",
      "[I 2025-12-20 13:43:48,857] Trial 10 finished with value: -10.297270817431396 and parameters: {'n_estimators': 200, 'learning_rate': 0.08331739326692464, 'max_depth': 9, 'min_child_weight': 1.1003680189353322, 'gamma': 4.7857414642842215, 'subsample': 0.6622537615202017, 'colsample_bytree': 0.971002746882751}. Best is trial 10 with value: -10.297270817431396.\n",
      "[I 2025-12-20 13:44:00,724] Trial 11 finished with value: -10.178956145520914 and parameters: {'n_estimators': 199, 'learning_rate': 0.0857129934786357, 'max_depth': 10, 'min_child_weight': 1.3242565458346165, 'gamma': 4.941901695760993, 'subsample': 0.6685188104383077, 'colsample_bytree': 0.9808004697948114}. Best is trial 11 with value: -10.178956145520914.\n",
      "[I 2025-12-20 13:44:18,600] Trial 12 finished with value: -13.465347144399251 and parameters: {'n_estimators': 200, 'learning_rate': 0.010640492423577506, 'max_depth': 10, 'min_child_weight': 1.0225048456101007, 'gamma': 4.832274699703345, 'subsample': 0.6597737445824761, 'colsample_bytree': 0.9969283597199657}. Best is trial 11 with value: -10.178956145520914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBR hyperparameters: {'n_estimators': 199, 'learning_rate': 0.0857129934786357, 'max_depth': 10, 'min_child_weight': 1.3242565458346165, 'gamma': 4.941901695760993, 'subsample': 0.6685188104383077, 'colsample_bytree': 0.9808004697948114}\n",
      "Cross-val error (per fold): [ 9.1783437   8.57243066 10.5692033   9.78780108 12.00761219  9.42579845\n",
      " 10.72285409  8.97732509 10.52192211 12.0262708 ]\n",
      "Mean Cross-val error: 10.178956145520914\n"
     ]
    }
   ],
   "source": [
    "# --- XGBR ---\n",
    "study3 = optuna.create_study(direction='maximize')\n",
    "study3.optimize(objective_xgbr, n_trials=100, timeout=300)\n",
    "\n",
    "best_params3r = study3.best_params\n",
    "print(\"Best XGBR hyperparameters:\", best_params3r)\n",
    "\n",
    "xgb_coordinate_final = XGBRegressor(**best_params3r, random_state=42, n_jobs=-1)\n",
    "\n",
    "cv_scores_xgb = cross_val_score(xgb_coordinate_final, X_train2, y_train2,\n",
    "                                cv=10, scoring=euclidean_scorer, n_jobs=-1)\n",
    "\n",
    "print(\"Cross-val error (per fold):\", -cv_scores_xgb)\n",
    "print(\"Mean Cross-val error:\", -cv_scores_xgb.mean())\n",
    "\n",
    "xgb_coordinate_final.fit(X_train2, y_train2)\n",
    "joblib.dump(xgb_coordinate_final, 'xgb_coordinate_pred_Tampere_reg.pkl')\n",
    "xgb_loaded2 = joblib.load('xgb_coordinate_pred_Tampere_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8afc6b1-1b50-495b-9291-79a6d389de45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 13:44:40,601] A new study created in memory with name: no-name-bb3661a5-85c7-45d2-abbb-35cea22a7345\n",
      "[I 2025-12-20 13:44:45,342] Trial 0 finished with value: 21.19525562535397 and parameters: {'n_estimators': 125, 'learning_rate': 0.023822288565009026, 'num_leaves': 79, 'max_depth': 8, 'min_child_samples': 83}. Best is trial 0 with value: 21.19525562535397.\n",
      "[I 2025-12-20 13:44:49,321] Trial 1 finished with value: 17.039273463461548 and parameters: {'n_estimators': 85, 'learning_rate': 0.4692901190640652, 'num_leaves': 58, 'max_depth': 3, 'min_child_samples': 52}. Best is trial 1 with value: 17.039273463461548.\n",
      "[I 2025-12-20 13:45:13,853] Trial 2 finished with value: 11.786818042701906 and parameters: {'n_estimators': 179, 'learning_rate': 0.033438093789682065, 'num_leaves': 50, 'max_depth': 17, 'min_child_samples': 18}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:21,177] Trial 3 finished with value: 13.33796899130759 and parameters: {'n_estimators': 102, 'learning_rate': 0.04774923886817546, 'num_leaves': 44, 'max_depth': 9, 'min_child_samples': 36}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:30,271] Trial 4 finished with value: 17.16729443902465 and parameters: {'n_estimators': 186, 'learning_rate': 0.1947327484437202, 'num_leaves': 57, 'max_depth': 6, 'min_child_samples': 57}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:47,381] Trial 5 finished with value: 12.451495227446113 and parameters: {'n_estimators': 124, 'learning_rate': 0.4343438315429811, 'num_leaves': 45, 'max_depth': 10, 'min_child_samples': 9}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:51,807] Trial 6 finished with value: 21.03597868158468 and parameters: {'n_estimators': 74, 'learning_rate': 0.014217979958808732, 'num_leaves': 34, 'max_depth': 14, 'min_child_samples': 47}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:55,258] Trial 7 finished with value: 19.380484213060708 and parameters: {'n_estimators': 154, 'learning_rate': 0.043739477984217526, 'num_leaves': 64, 'max_depth': 15, 'min_child_samples': 75}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:45:58,236] Trial 8 finished with value: 19.521245275840958 and parameters: {'n_estimators': 110, 'learning_rate': 0.22414221903789272, 'num_leaves': 73, 'max_depth': 24, 'min_child_samples': 79}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 13:47:11,751] Trial 9 finished with value: 23.395063255269186 and parameters: {'n_estimators': 57, 'learning_rate': 0.01809180519319029, 'num_leaves': 52, 'max_depth': 21, 'min_child_samples': 60}. Best is trial 2 with value: 11.786818042701906.\n",
      "[I 2025-12-20 14:10:49,191] Trial 10 finished with value: 11.136248186129714 and parameters: {'n_estimators': 196, 'learning_rate': 0.10230937072142514, 'num_leaves': 20, 'max_depth': 30, 'min_child_samples': 8}. Best is trial 10 with value: 11.136248186129714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LGBR hyperparameters: {'n_estimators': 196, 'learning_rate': 0.10230937072142514, 'num_leaves': 20, 'max_depth': 30, 'min_child_samples': 8}\n",
      "Cross-val error (per fold): [10.00301613 11.62085132 11.14955043 10.54061378 11.75481306 13.00169678\n",
      " 12.46781435  9.55511876 11.26225029 10.00675696]\n",
      "Mean Cross-val error: 11.136248186129714\n"
     ]
    }
   ],
   "source": [
    "# --- LGBR ---\n",
    "study5 = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study5.optimize(objective_lgbr, n_trials=100, timeout=300)\n",
    "\n",
    "best_params5r = study5.best_params\n",
    "print(\"Best LGBR hyperparameters:\", best_params5r)\n",
    "\n",
    "# Train final model using best params\n",
    "base_model_final = lgb.LGBMRegressor(**best_params5r, random_state=SEED, n_jobs=-1)\n",
    "lgb_coordinate_final = MultiOutputRegressor(base_model_final)\n",
    "\n",
    "# Cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "cv_scores_lgbm = cross_val_score(\n",
    "    lgb_coordinate_final, X_train2, y_train2,\n",
    "    cv=cv, scoring=euclidean_scorer, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Positive error conversion\n",
    "cv_errors_lgbm = -cv_scores_lgbm\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-val error (per fold):\", cv_errors_lgbm)\n",
    "print(\"Mean Cross-val error:\", cv_errors_lgbm.mean())\n",
    "\n",
    "# Train on full training set\n",
    "lgb_coordinate_final.fit(X_train2, y_train2)\n",
    "\n",
    "# Save and reload\n",
    "joblib.dump(lgb_coordinate_final, 'multioutput_lgbm_regressor.pkl')\n",
    "multi_model_final = joblib.load('multioutput_lgbm_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdfdf6e7-3a96-40e2-add6-4f90b3a2a350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 14:21:42,883] A new study created in memory with name: no-name-44fb69be-264c-4c18-98be-db6a15821be3\n",
      "[I 2025-12-20 14:21:53,679] Trial 0 finished with value: 23.703565678561453 and parameters: {'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 7, 'n_estimators': 249, 'learning_rate': 0.40108745769050896}. Best is trial 0 with value: 23.703565678561453.\n",
      "[I 2025-12-20 14:22:31,363] Trial 1 finished with value: 11.148477770061545 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'n_estimators': 228, 'learning_rate': 0.6495094675156889}. Best is trial 1 with value: 11.148477770061545.\n",
      "[I 2025-12-20 14:23:04,525] Trial 2 finished with value: 10.090080930061118 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'n_estimators': 204, 'learning_rate': 0.08501175887716055}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:23:23,314] Trial 3 finished with value: 14.047443676403692 and parameters: {'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10, 'n_estimators': 168, 'learning_rate': 0.3620772883250203}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:23:56,410] Trial 4 finished with value: 10.63138874133596 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'n_estimators': 210, 'learning_rate': 0.4714702896371017}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:24:29,968] Trial 5 finished with value: 11.374839600730954 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8, 'n_estimators': 206, 'learning_rate': 0.2805882246929285}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:24:54,433] Trial 6 finished with value: 17.243045764174738 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 5, 'n_estimators': 206, 'learning_rate': 0.3796102204413861}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:25:15,544] Trial 7 finished with value: 12.742996576621014 and parameters: {'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'n_estimators': 137, 'learning_rate': 0.5256424363198482}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:25:24,129] Trial 8 finished with value: 22.993563311983984 and parameters: {'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 7, 'n_estimators': 183, 'learning_rate': 0.855552377683533}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:25:33,580] Trial 9 finished with value: 11.761514994193433 and parameters: {'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 10, 'n_estimators': 53, 'learning_rate': 0.08146718180711615}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:26:12,102] Trial 10 finished with value: 11.605242712629835 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2, 'n_estimators': 296, 'learning_rate': 0.1366217109583572}. Best is trial 2 with value: 10.090080930061118.\n",
      "[I 2025-12-20 14:26:28,564] Trial 11 finished with value: 10.080129199704832 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'n_estimators': 129, 'learning_rate': 0.9669608356459181}. Best is trial 11 with value: 10.080129199704832.\n",
      "[I 2025-12-20 14:26:38,859] Trial 12 finished with value: 10.207882079761822 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'n_estimators': 92, 'learning_rate': 0.9805723187410847}. Best is trial 11 with value: 10.080129199704832.\n",
      "[I 2025-12-20 14:26:52,580] Trial 13 finished with value: 11.156524405829996 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4, 'n_estimators': 129, 'learning_rate': 0.7073176319342512}. Best is trial 11 with value: 10.080129199704832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Regressor hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'n_estimators': 129, 'learning_rate': 0.9669608356459181}\n",
      "AdaBoost Cross-val error (per fold): [ 9.83564491 10.38530258  9.82915121  9.26586494 10.02244272 12.87155687\n",
      " 10.08520404 10.44977661  8.68515385  9.37119427]\n",
      "AdaBoost Mean Cross-val error: 10.080129199704832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "\n",
    "# --- AdaBoost Regressor Optimization ---\n",
    "study_ab_r = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study_ab_r.optimize(objective_adaboost_r, n_trials=50, timeout=300)\n",
    "\n",
    "best_params_ab_r = study_ab_r.best_params\n",
    "print(\"Best AdaBoost Regressor hyperparameters:\", best_params_ab_r)\n",
    "\n",
    "# --- Extract AdaBoost-specific parameters ---\n",
    "ada_params = {\n",
    "    'n_estimators': best_params_ab_r.pop('n_estimators'),\n",
    "    'learning_rate': best_params_ab_r.pop('learning_rate'),\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "# Base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeRegressor(**best_params_ab_r, random_state=SEED)\n",
    "\n",
    "# Final AdaBoost Regressor wrapped with MultiOutputRegressor for 2D output\n",
    "ab_coordinate_final = MultiOutputRegressor(\n",
    "    AdaBoostRegressor(\n",
    "        estimator=base_estimator,\n",
    "        **ada_params\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Cross-validation ---\n",
    "cv_scores_ab = cross_val_score(\n",
    "    ab_coordinate_final,\n",
    "    X_train2,\n",
    "    y_train2,\n",
    "    cv=cv,\n",
    "    scoring=euclidean_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"AdaBoost Cross-val error (per fold):\", -cv_scores_ab)\n",
    "print(\"AdaBoost Mean Cross-val error:\", -cv_scores_ab.mean())\n",
    "\n",
    "# --- Train on full training set and save model ---\n",
    "ab_coordinate_final.fit(X_train2, y_train2)\n",
    "joblib.dump(ab_coordinate_final, 'adaboost_coordinate_pred_Tampere_reg.pkl')\n",
    "\n",
    "# Optional: Load the model back\n",
    "ab_loaded = joblib.load('adaboost_coordinate_pred_Tampere_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b351054a-4298-474c-adf6-70698d4b3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = [\n",
    "        (\"KNN\", knn_coordinate_final),\n",
    "        (\"RF\", rf_coordinate_final),\n",
    "        (\"LGB\", lgb_coordinate_final),\n",
    "        (\"XGB\", xgb_coordinate_final),\n",
    "        (\"AB\", ab_coordinate_final)\n",
    "    ]\n",
    "\n",
    "accuracy_knn = cv_scores_knn.mean()\n",
    "accuracy_rf = cv_scores_rf.mean()\n",
    "accuracy_lgb = cv_scores_lgbm.mean()\n",
    "accuracy_xgb = cv_scores_xgb.mean()\n",
    "accuracy_ab = cv_scores_ab.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcba5c1d-e852-44eb-8c00-bdc87cacb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(ensemble, X, model_scores):\n",
    "    \"\"\"\n",
    "    Weighted ensemble prediction for regression.\n",
    "    Each model's predictions are weighted by its CV-based score.\n",
    "    \"\"\"\n",
    "    # Collect predictions from all models\n",
    "    preds = np.array([m.predict(X) for _, m in ensemble])\n",
    "\n",
    "    # Compute normalized weights based on model scores\n",
    "    weights = np.array([model_scores[name] for name, _ in ensemble])\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    # Weighted average across models\n",
    "    weighted_preds = np.tensordot(weights, preds, axes=(0, 0))\n",
    "\n",
    "    return weighted_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7b5c7-49cf-4df0-9c6d-7f65a0ac5abd",
   "metadata": {},
   "source": [
    "# IEO-CVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "431b720f-cc79-49a1-a5bd-8bf219d1f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def ieo_cvv_ensemble_selection_reg(models, X_train, y_train, X_test, y_test, cv=10, patience=3):\n",
    "    print(\"Initializing Iterative Ensemble Optimization with CV Voting (IEO-CVV) using Mean Euclidean Error...\")\n",
    "\n",
    "    def mean_euclidean_error(y_true, y_pred):\n",
    "        return np.mean(np.linalg.norm(y_true - y_pred, axis=1))\n",
    "\n",
    "    # --- Step 1: Cross-validated predictions and MEE scores ---\n",
    "    model_scores = {}\n",
    "    model_preds = {}\n",
    "\n",
    "    for name, model in models:\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        y_pred_cv = cross_val_predict(model, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "        mee = mean_euclidean_error(y_train, y_pred_cv)\n",
    "        model_scores[name] = -mee  \n",
    "        model_preds[name] = y_pred_cv\n",
    "        print(f\"{name} CV Mean Euclidean Error: {mee:.4f}\")\n",
    "\n",
    "    # Sort models by performance (lowest MEE first)\n",
    "    sorted_models = sorted(models, key=lambda m: model_scores[m[0]], reverse=True)\n",
    "\n",
    "    # --- Weighted average ensemble prediction (CV stage) ---\n",
    "    def ensemble_predict_cv(selected_model_names):\n",
    "        preds = np.array([model_preds[name] for name in selected_model_names])  # shape: (n_models, n_samples, n_outputs)\n",
    "        weights = np.array([model_scores[name] for name in selected_model_names])\n",
    "        weights = weights / weights.sum()\n",
    "        return np.tensordot(weights, preds, axes=(0, 0))\n",
    "\n",
    "    # --- Step 2: Initialize with top 2 models ---\n",
    "    ensemble = sorted_models[:2]\n",
    "    ensemble_names = [name for name, _ in ensemble]\n",
    "    y_ensemble_cv = ensemble_predict_cv(ensemble_names)\n",
    "    best_score = -mean_euclidean_error(y_train, y_ensemble_cv)\n",
    "    print(f\"Initial Ensemble: {ensemble_names} - Train MEE: {-best_score:.4f}\")\n",
    "\n",
    "    # --- Step 3: Iterative forward selection with backward pruning ---\n",
    "    patience_counter = 0\n",
    "    remaining_models = sorted_models[2:]\n",
    "\n",
    "    while remaining_models and patience_counter < patience:\n",
    "        improved = False\n",
    "\n",
    "        name, model = remaining_models.pop(0)\n",
    "        temp_ensemble = ensemble + [(name, model)]\n",
    "        temp_names = [n for n, _ in temp_ensemble]\n",
    "\n",
    "        y_pred_temp = ensemble_predict_cv(temp_names)\n",
    "        temp_score = -mean_euclidean_error(y_train, y_pred_temp)\n",
    "\n",
    "        if temp_score > best_score:\n",
    "            ensemble = temp_ensemble\n",
    "            best_score = temp_score\n",
    "            patience_counter = 0\n",
    "            print(f\"Added {name} - Improved MEE: {-temp_score:.4f}\")\n",
    "\n",
    "            # --- Backward pruning ---\n",
    "            pruned = True\n",
    "            while pruned and len(ensemble) > 1:\n",
    "                pruned = False\n",
    "                for n, _ in ensemble:\n",
    "                    if n == name:\n",
    "                        continue\n",
    "                    temp_pruned = [(x, y) for x, y in ensemble if x != n]\n",
    "                    temp_names_pruned = [x for x, _ in temp_pruned]\n",
    "                    y_pred_pruned = ensemble_predict_cv(temp_names_pruned)\n",
    "                    pruned_score = -mean_euclidean_error(y_train, y_pred_pruned)\n",
    "                    if pruned_score >= best_score:\n",
    "                        print(f\"Pruned {n} - MEE improved/maintained: {-pruned_score:.4f}\")\n",
    "                        ensemble = temp_pruned\n",
    "                        best_score = pruned_score\n",
    "                        pruned = True\n",
    "                        break\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Ignored {name} - No improvement: {-temp_score:.4f} (Patience: {patience_counter}/{patience})\")\n",
    "\n",
    "    # --- Step 4: Final weights based on CV performance ---\n",
    "    final_names = [n for n, _ in ensemble]\n",
    "    weights = {name: model_scores[name] for name in final_names}\n",
    "    total = sum(weights.values())\n",
    "    weights = {k: v / total for k, v in weights.items()}\n",
    "\n",
    "    print(\"Final Ensemble Members:\", final_names)\n",
    "    print(\"Final Ensemble Train MEE:\", -best_score)\n",
    "\n",
    "    # --- Step 5: Retrain models and evaluate on test set ---\n",
    "    print(\"\\nRetraining final models and evaluating on test set...\")\n",
    "    for name, model in ensemble:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    def ensemble_predict_test(selected_models, X):\n",
    "        preds = np.array([model.predict(X) for _, model in selected_models])\n",
    "        wts = np.array([model_scores[name] for name, _ in selected_models])\n",
    "        wts = wts / wts.sum()\n",
    "        return np.tensordot(wts, preds, axes=(0, 0))\n",
    "\n",
    "    y_pred_test = ensemble_predict_test(ensemble, X_test)\n",
    "    test_mee = mean_euclidean_error(y_test, y_pred_test)\n",
    "    print(\"Final Ensemble Test MEE:\", test_mee)\n",
    "\n",
    "    return ensemble, -best_score, weights, test_mee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83f8d314-df9b-4ae4-96f1-f849220a3617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Iterative Ensemble Optimization with CV Voting (IEO-CVV) using Mean Euclidean Error...\n",
      "Evaluating KNN...\n",
      "KNN CV Mean Euclidean Error: 10.0008\n",
      "Evaluating RF...\n",
      "RF CV Mean Euclidean Error: 9.8822\n",
      "Evaluating LGB...\n",
      "LGB CV Mean Euclidean Error: 10.6842\n",
      "Evaluating XGB...\n",
      "XGB CV Mean Euclidean Error: 10.1772\n",
      "Evaluating AB...\n",
      "AB CV Mean Euclidean Error: 10.1071\n",
      "Initial Ensemble: ['RF', 'KNN'] - Train MEE: 9.1074\n",
      "Added AB - Improved MEE: 9.0547\n",
      "Added XGB - Improved MEE: 8.9350\n",
      "Pruned RF - MEE improved/maintained: 8.9219\n",
      "Ignored LGB - No improvement: 9.0226 (Patience: 1/3)\n",
      "Final Ensemble Members: ['KNN', 'AB', 'XGB']\n",
      "Final Ensemble Train MEE: 8.921859860653061\n",
      "\n",
      "Retraining final models and evaluating on test set...\n",
      "Final Ensemble Test MEE: 8.655408246857482\n",
      "Training time: 5158.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run greedy ensemble selection for regression using Mean Euclidean Distance\n",
    "ensemble2r, train_score2r, ensemble_weights2r, test_score2r = ieo_cvv_ensemble_selection_reg(\n",
    "    models2,\n",
    "    X_train2, y_train2,   # training data\n",
    "    X_test2, y_test2,     # test data\n",
    "    cv=10,                # cross-validation folds\n",
    ")\n",
    "\n",
    "end_time2 = time.time()\n",
    "\n",
    "training_time2 = end_time2 - start_time2\n",
    "print(f\"Training time: {training_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30157d1a-a55d-40a2-b370-34619e0569d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 11.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Predict target coordinates using the final ensemble\n",
    "start_time4 = time.time()\n",
    "\n",
    "y_target_predictions2 = ensemble_predict(ensemble2r, X_target, ensemble_weights2r)\n",
    "\n",
    "end_time4 = time.time()\n",
    "\n",
    "training_time4 = end_time4 - start_time4\n",
    "print(f\"Training time: {training_time4:.2f} seconds\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a6fb8f5-01e3-48bb-82b7-eadf65998024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Mean Euclidean Distance (Target set): 8.649110444785647\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ensemble predictions on target set using Euclidean distance\n",
    "euclidean_errors = np.linalg.norm(y_target_coordinate - y_target_predictions2, axis=1)\n",
    "med_ensemble = euclidean_errors.mean()\n",
    "\n",
    "print(\"Ensemble Mean Euclidean Distance (Target set):\", med_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f13af3aa-7bc9-49ac-9342-a4d70877a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinate2 = pd.DataFrame(y_target_predictions2, columns=['x', 'y'])\n",
    "df_floor2 = pd.DataFrame(y_floor_predictions2, columns=['Floor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a933ff9-d535-4bc7-a023-448aa8aede6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined2 = pd.concat([df_coordinate2, df_floor2], axis=1)\n",
    "df_combined2.to_excel('Tampere Prediction2_TPE_PS.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
